{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thirdParagraphBioTagging.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "obGBWFLnIypX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9a5db4b-d218-4b6d-de5a-83e21ac92f18"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install transformers\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy\n",
        "!pip install kss\n",
        "%cd /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
        "!pwd\n",
        "from frameBERT import frame_parser\n",
        "path=\"/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\"\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778kB 2.8MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 8.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=f61eaf45a057afa8b4f8282875c13f486d395a437159cd37b5b1625024db9f6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Hit:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,854 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [882 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,334 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,037 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [27.1 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [116 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,413 kB]\n",
            "Get:21 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [895 kB]\n",
            "Fetched 7,830 kB in 3s (2,642 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "g++ set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 10 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 40.7 MB of archives.\n",
            "After this operation, 153 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u265-b01-0ubuntu2~18.04 [27.5 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u265-b01-0ubuntu2~18.04 [69.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u265-b01-0ubuntu2~18.04 [8,262 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u265-b01-0ubuntu2~18.04 [1,610 kB]\n",
            "Fetched 40.7 MB in 2s (20.5 MB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../1-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../2-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../3-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../4-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../5-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../6-openjdk-8-jre-headless_8u265-b01-0ubuntu2~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u265-b01-0ubuntu2~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../7-openjdk-8-jre_8u265-b01-0ubuntu2~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u265-b01-0ubuntu2~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../8-openjdk-8-jdk-headless_8u265-b01-0ubuntu2~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u265-b01-0ubuntu2~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../9-openjdk-8-jdk_8u265-b01-0ubuntu2~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u265-b01-0ubuntu2~18.04) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u265-b01-0ubuntu2~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u265-b01-0ubuntu2~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u265-b01-0ubuntu2~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u265-b01-0ubuntu2~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.4MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 9.9MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/49/725710351d78d26c65337b1e3b322d7b27b34b704535ab56afc0d9ab0ffd/JPype1-1.0.1-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, tweepy, JPype1, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.0.1 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n",
            "Collecting kss\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/bb/4772901b3b934ac204f32a0bd6fc0567871d8378f9bbc7dd5fd5e16c6ee7/kss-1.3.1.tar.gz\n",
            "Building wheels for collected packages: kss\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-1.3.1-cp36-cp36m-linux_x86_64.whl size=251562 sha256=d0f027e92e188a778f558e0a9778dc0317468927e73cf96ec8272eff8d06a70f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/98/d1/53f75f89925cd95779824778725ee3fa36e7aa55ed26ad54a8\n",
            "Successfully built kss\n",
            "Installing collected packages: kss\n",
            "Successfully installed kss-1.3.1\n",
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "\n",
            "###DEVICE: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbmSXGrwJ585",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import kss\n",
        "from konlpy.tag import Hannanum\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import heapq\n",
        "import pandas as pd\n",
        "from operator import itemgetter "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v5o0el7I9ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text ='''\n",
        "TEXT2PPTXì˜ êµ¬í˜„í•˜ê¸° ìœ„í•´ two track processë¥¼ ê±°ì³¤ìŠµë‹ˆë‹¤. ëŒ€ë³¸ì„ í”¼í”¼í‹°ë¡œ ì˜®ê¸°ê¸° ì „ì— ìš”ì•½í•˜ê³  ë¶„ì„í•˜ê¸° ìœ„í•´ ìì—°ì–´ì²˜ë¦¬ì˜ ìµœì‹  ê¸°ìˆ ì„ ë‹¤ìˆ˜ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ íŒŒì´ì¬ì—ì„œ íŒŒì›Œí¬ì¸íŠ¸ì˜ ì†ŒìŠ¤ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ xml ì½”ë“œë¥¼ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼ ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ì“°ì¸ ëŒ€ë³¸ì„ í…2í”¼ì— ì œê³µí•˜ë©´ ë†’ì€ ìˆ˜ì¤€ì˜ í”¼í”¼í‹°ë¡œ ì œê³µí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Af1flDKI9M8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "b89cf904-5fc9-4a1c-ed53-fe0ad7d4541c"
      },
      "source": [
        "ls = kss.split_sentences(text)\n",
        "print(\"ğŸ§ Numbers of sentences \",len(ls))\n",
        "parser = frame_parser.FrameParser(model_path=path, language='ko')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ§ Numbers of sentences  4\n",
            "srl model: framenet\n",
            "language: ko\n",
            "version: 1.2\n",
            "using viterbi: False\n",
            "using masking: True\n",
            "pretrained BERT: bert-base-multilingual-cased\n",
            "using TGT special token: True\n",
            "used dictionary:\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lu2idx.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lufrmap.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
            "...loaded model path: /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "...model is loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred_logits = sm(masked_logit).view(1,-1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIph64I5OnLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split(object):\n",
        "  ls = kss.split_sentences(object)\n",
        "  return ls\n",
        "\n",
        "def parse(text):\n",
        "  parser = frame_parser.FrameParser(model_path=path, language='ko')\n",
        "  parsed = parser.parser(text, sent_id='1', result_format='conll')\n",
        "  \n",
        "def findBegin(parsed):\n",
        "  a = [0]*10\n",
        "  for _ in range(len(parsed)):\n",
        "    a[_]=parsed\n",
        "    tagged = a[_][3]\n",
        "    words = a[_][0]\n",
        "    for element in tagged:\n",
        "      swb = element.startswith(\"B\")\n",
        "      if swb:\n",
        "        b = tagged[swb]\n",
        "        \n",
        "        idx = tagged.index(b)-1\n",
        "        role = tagged[idx].split(\"-\")[1]\n",
        "        beginning = words[idx]\n",
        "\n",
        "  \n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHzVCWhCSIkU",
        "colab_type": "text"
      },
      "source": [
        "### ì²« ë²ˆì§¸ ë¬¸ì¥ì€ ì´ë¯¸ summarizationì— ì˜í•´ í¬í•¨ëœ ë¬¸ì¥ì´ë¯€ë¡œ relation extractionì— ì˜í•´ì„œ ì´ì¤‘ìœ¼ë¡œ í¬í•¨ì‹œí‚¤ì§€ ì•ŠëŠ” ê²ƒì´ ë§ë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW1KnYj3VmqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7675ce7c-d084-4e5b-a48f-81e4081521f2"
      },
      "source": [
        "h.pos(ls[0])"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('TEXT2PPTX', 'N'),\n",
              " ('ì˜', 'J'),\n",
              " ('êµ¬í˜„', 'N'),\n",
              " ('í•˜', 'X'),\n",
              " ('ê¸°', 'E'),\n",
              " ('ìœ„í•˜', 'P'),\n",
              " ('ì–´', 'E'),\n",
              " ('two', 'F'),\n",
              " ('track', 'F'),\n",
              " ('process', 'F'),\n",
              " ('ë¥¼', 'J'),\n",
              " ('ê±°ì¹˜', 'P'),\n",
              " ('ì—ˆìŠµë‹ˆë‹¤', 'E'),\n",
              " ('.', 'S')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7zGTQO4BUO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "547d7aba-c69a-4494-ecea-766a9b179cfc"
      },
      "source": [
        "# 1st sentence : GOALS & MEANS \n",
        "\n",
        "parsed = parser.parser(ls[0], sent_id='1', result_format='conll')\n",
        "words = parsed[0][0]\n",
        "print(\"ğŸ˜€ Words vector from sentence \",words)\n",
        "q = [-1]*len(parsed)\n",
        "for i in range(len(parsed)):\n",
        "  count=0\n",
        "  for element in parsed[i][3]:\n",
        "    if element.startswith(\"O\"):\n",
        "      count+=1\n",
        "  q[i] = len(words) - count\n",
        "\n",
        "\n",
        "print(\"Number of parsed candidates \",len(parsed))\n",
        "print(q, heapq.nlargest(2, q)) # ì²«ë²ˆì§¸ ê²½ìš° ì‚¬ìš©\n",
        "\n",
        "words = parsed[0][0]\n",
        "roles = parsed[0][2]\n",
        "tagged = parsed[0][3]\n",
        "for idx in range(len(tagged)):\n",
        "  try:\n",
        "    roles[i] = tagged[i].split(\"-\")[1]\n",
        "  except:\n",
        "    roles[i] = tagged[i].split(\"-\")[0]\n",
        "\n",
        "print(\"roles \",roles)\n",
        "\n",
        "goals = []\n",
        "means = []\n",
        "for _ in range(len(words)):\n",
        "  if roles[_]==\"Goal\":\n",
        "    goals.append(words[_])\n",
        "  if roles[_]=='Means':\n",
        "    means.append(words[_])\n",
        "\n",
        "# MEANS\n",
        "MEANS = ' '.join(means)\n",
        "pos = h.pos(MEANS)\n",
        "imp = []\n",
        "for tup in h.pos(MEANS):\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "MEANS_TRUNCATED = ' '.join(imp)\n",
        "print(MEANS_TRUNCATED)\n",
        "\n",
        "# GOALS\n",
        "GOAL = ' '.join(goals)\n",
        "pos = h.pos(GOAL)\n",
        "imp = []\n",
        "for tup in h.pos(GOAL):\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "GOAL_TRUNCATED = ' '.join(imp)\n",
        "print(GOAL_TRUNCATED)\n",
        "\n",
        "final_string = MEANS_TRUNCATED + ' -- >' + GOAL_TRUNCATED\n",
        "print(\"ğŸ˜€ final string to be inserted\",final_string)\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred_logits = sm(masked_logit).view(1,-1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ğŸ˜€ Words vector from sentence  ['TEXT2PPTXì˜', 'êµ¬í˜„í•˜ê¸°', 'ìœ„í•´', 'two', 'track', 'processë¥¼', 'ê±°ì³¤ìŠµë‹ˆë‹¤.']\n",
            "Number of parsed candidates  2\n",
            "[5, 3] [5, 3]\n",
            "roles  ['_', 'Goal', 'Purpose', '_', '_', '_', '_']\n",
            "\n",
            "êµ¬í˜„í•˜ê¸°\n",
            "ğŸ˜€ final string to be inserted  -- >êµ¬í˜„í•˜ê¸°\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9zsJryuBRri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "dc2971b6-b2a7-444a-bcbe-9f3f7bef79f0"
      },
      "source": [
        "# 2nd sentence : PURPOSE & INSTRUMENT\n",
        "parsed = parser.parser(ls[1], sent_id='1', result_format='conll')\n",
        "words = parsed[0][0]\n",
        "print(\"ğŸ˜€ Words vector from sentence \",words)\n",
        "q = [-1]*len(parsed)\n",
        "for i in range(len(parsed)):\n",
        "  count=0\n",
        "  for element in parsed[i][3]:\n",
        "    if element.startswith(\"O\"):\n",
        "      count+=1\n",
        "  q[i] = len(words) - count\n",
        "\n",
        "\n",
        "print(\"Number of parsed candidates \",len(parsed))\n",
        "print(q, heapq.nlargest(3, q))\n",
        "print(itemgetter(*[1,5])(parsed))\n",
        "candidates = itemgetter(*[1,8])(parsed)\n",
        "for _ in candidates:\n",
        "  words = _[0]\n",
        "  tagged = _[3]\n",
        "  print(\"tagged vector of candidates: \",tagged)\n",
        "  roles = _[2]\n",
        "  for i in range(len(parsed)):\n",
        "    try:\n",
        "      roles[i] = tagged[i].split(\"-\")[1]\n",
        "    except:\n",
        "      roles[i] = tagged[i].split(\"-\")[0]\n",
        "  print(roles,f'Tagged words for the roles : {tagged}')\n",
        "# roles are selected as the one with purpose and instrument\n",
        "\n",
        "purpose = []\n",
        "instrument = []\n",
        "for _ in range(len(words)):\n",
        "  if roles[_]==\"Purpose\":\n",
        "    purpose.append(words[_])\n",
        "    \n",
        "  elif roles[_]==\"Instrument\":\n",
        "    instrument.append(words[_])\n",
        "    \n",
        "  elif roles[_]!=\"_\": # using í¬í•¨\n",
        "    instrument.append(words[_])\n",
        "print(\"Instrument: \",instrument)\n",
        "print(\"Purpose: \",purpose)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# PURPOSE\n",
        "PURPOSE = ' '.join(purpose)\n",
        "pos = h.pos(PURPOSE)\n",
        "imp = []\n",
        "for tup in pos:\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "PURPOSE_TRUNCATED = ' '.join(imp)\n",
        "print(PURPOSE_TRUNCATED)\n",
        "\n",
        "# INSTRUMENT\n",
        "INSTRUMENT = ' '.join(instrument)\n",
        "pos = h.pos(INSTRUMENT)\n",
        "imp = []\n",
        "for tup in pos:\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "INST_TRUNCATED = ' '.join(imp)\n",
        "print(INST_TRUNCATED)\n",
        "\n",
        "final_string = INST_TRUNCATED+ ' â¡ï¸' + PURPOSE_TRUNCATED \n",
        "print(\"ğŸ˜€ final string to be inserted \", final_string)\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred_logits = sm(masked_logit).view(1,-1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ğŸ˜€ Words vector from sentence  ['ëŒ€ë³¸ì„', 'í”¼í”¼í‹°ë¡œ', 'ì˜®ê¸°ê¸°', 'ì „ì—', 'ìš”ì•½í•˜ê³ ', 'ë¶„ì„í•˜ê¸°', 'ìœ„í•´', 'ìì—°ì–´ì²˜ë¦¬ì˜', 'ìµœì‹ ', 'ê¸°ìˆ ì„', 'ë‹¤ìˆ˜', 'ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.']\n",
            "Number of parsed candidates  9\n",
            "[2, 11, 4, 0, 6, 1, 1, 1, 11] [11, 11, 6]\n",
            "([['ëŒ€ë³¸ì„', 'í”¼í”¼í‹°ë¡œ', 'ì˜®ê¸°ê¸°', 'ì „ì—', 'ìš”ì•½í•˜ê³ ', 'ë¶„ì„í•˜ê¸°', 'ìœ„í•´', 'ìì—°ì–´ì²˜ë¦¬ì˜', 'ìµœì‹ ', 'ê¸°ìˆ ì„', 'ë‹¤ìˆ˜', 'ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.'], ['_', '_', '_', 'ì „.n', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', 'Time_vector', '_', '_', '_', '_', '_', '_', '_', '_'], ['B-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'O', 'B-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event']], [['ëŒ€ë³¸ì„', 'í”¼í”¼í‹°ë¡œ', 'ì˜®ê¸°ê¸°', 'ì „ì—', 'ìš”ì•½í•˜ê³ ', 'ë¶„ì„í•˜ê¸°', 'ìœ„í•´', 'ìì—°ì–´ì²˜ë¦¬ì˜', 'ìµœì‹ ', 'ê¸°ìˆ ì„', 'ë‹¤ìˆ˜', 'ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.'], ['_', '_', '_', '_', '_', '_', '_', '_', 'ìµœì‹ .n', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', 'Relative_time', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Focal_participant', 'O', 'O']])\n",
            "tagged vector of candidates:  ['B-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'O', 'B-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event']\n",
            "['Landmark_event', 'Landmark_event', 'Landmark_event', 'O', 'Event', 'Event', 'Event', 'Event', 'Event', '_', '_', '_'] Tagged words for the roles : ['B-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'O', 'B-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event']\n",
            "tagged vector of candidates:  ['B-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'B-Instrument', 'I-Instrument', 'I-Instrument', 'B-Manner', 'O']\n",
            "['Purpose', 'Purpose', 'Purpose', 'Purpose', 'Purpose', 'Purpose', 'Purpose', 'Instrument', 'Instrument', '_', '_', 'Using'] Tagged words for the roles : ['B-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'B-Instrument', 'I-Instrument', 'I-Instrument', 'B-Manner', 'O']\n",
            "Instrument:  ['ìì—°ì–´ì²˜ë¦¬ì˜', 'ìµœì‹ ', 'ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.']\n",
            "Purpose:  ['ëŒ€ë³¸ì„', 'í”¼í”¼í‹°ë¡œ', 'ì˜®ê¸°ê¸°', 'ì „ì—', 'ìš”ì•½í•˜ê³ ', 'ë¶„ì„í•˜ê¸°', 'ìœ„í•´']\n",
            "ëŒ€ë³¸ í”¼í”¼í‹° ì „ ìš”ì•½ ë¶„ì„\n",
            "ìì—°ì–´ì²˜ë¦¬ ìµœì‹  ì‚¬ìš©\n",
            "ğŸ˜€ final string to be inserted  ìì—°ì–´ì²˜ë¦¬ ìµœì‹  ì‚¬ìš© â¡ï¸ëŒ€ë³¸ í”¼í”¼í‹° ì „ ìš”ì•½ ë¶„ì„\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxZxxnMiVuKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "945f2131-26cd-44d3-cd1c-c00ef0bb5f39"
      },
      "source": [
        "# 3rd sentence : Goal - Means\n",
        "parsed = parser.parser(ls[2], sent_id='1', result_format='conll')\n",
        "words = parsed[0][0]\n",
        "print(\"Words vector from sentence \",words)\n",
        "q = [-1]*len(parsed)\n",
        "for i in range(len(parsed)):\n",
        "  count=0\n",
        "  for element in parsed[i][3]:\n",
        "    if element.startswith(\"O\"):\n",
        "      count+=1\n",
        "  q[i] = len(words) - count\n",
        "\n",
        "print(q, heapq.nlargest(3, q))\n",
        "\n",
        "a,b,c=parsed\n",
        "tagged = b[3]\n",
        "for i in range(len(tagged)):\n",
        "  try:\n",
        "    roles[i] = tagged[i].split(\"-\")[1]\n",
        "  except:\n",
        "    roles[i] = tagged[i].split(\"-\")[0]\n",
        "\n",
        "\n",
        "\n",
        "goals = []\n",
        "means = []\n",
        "for _ in range(len(words)):\n",
        "  if roles[_]==\"Goal\":\n",
        "    goals.append(words[_])\n",
        "  if roles[_]=='Means':\n",
        "    means.append(words[_])\n",
        "\n",
        "# MEANS\n",
        "MEANS = ' '.join(means)\n",
        "pos = h.pos(MEANS)\n",
        "imp = []\n",
        "for tup in h.pos(MEANS):\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "MEANS_TRUNCATED = ' '.join(imp)\n",
        "print(MEANS_TRUNCATED)\n",
        "\n",
        "# GOALS\n",
        "GOAL = ' '.join(goals)\n",
        "pos = h.pos(GOAL)\n",
        "imp = []\n",
        "for tup in h.pos(GOAL):\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "GOAL_TRUNCATED = ' '.join(imp)\n",
        "print(GOAL_TRUNCATED)\n",
        "\n",
        "final_string = MEANS_TRUNCATED + ' -- >' + GOAL_TRUNCATED\n",
        "print(\"ğŸ˜€ final string to be inserted\",final_string)\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred_logits = sm(masked_logit).view(1,-1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Words vector from sentence  ['ë˜í•œ', 'íŒŒì´ì¬ì—ì„œ', 'íŒŒì›Œí¬ì¸íŠ¸ì˜', 'ì†ŒìŠ¤ì—', 'ì ‘ê·¼í•˜ê¸°', 'ìœ„í•´', 'xml', 'ì½”ë“œë¥¼', 'ì‹¬ì¸µì ìœ¼ë¡œ', 'ë¶„ì„í–ˆìŠµë‹ˆë‹¤.']\n",
            "[2, 8, 3] [8, 3, 2]\n",
            "askdf\n",
            "askdf\n",
            "askdf\n",
            "askdf\n",
            "   \n",
            "ì½”ë“œ ì‹¬ì¸µì  ë¶„ì„\n",
            "íŒŒì´ì¬ íŒŒì›Œí¬ì¸íŠ¸ ì†ŒìŠ¤ ì ‘ê·¼í•˜ê¸°\n",
            "ğŸ˜€ final string to be inserted ì½”ë“œ ì‹¬ì¸µì  ë¶„ì„-->íŒŒì´ì¬ íŒŒì›Œí¬ì¸íŠ¸ ì†ŒìŠ¤ ì ‘ê·¼í•˜ê¸°\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQxErkIzOj0W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "8cbbe6fe-11dd-4e8b-a633-1aff0b26911a"
      },
      "source": [
        "# # Fourth Sentence\n",
        "\n",
        "# parsed = parser.parser(ls[3], sent_id='1', result_format='conll')\n",
        "# words = parsed[0][0]\n",
        "# print(\"ğŸ˜€ Words vector from sentence \",words)\n",
        "# q = [-1]*len(parsed)\n",
        "# for i in range(len(parsed)):\n",
        "#   count=0\n",
        "#   for element in parsed[i][3]:\n",
        "#     if element.startswith(\"O\"):\n",
        "#       count+=1\n",
        "#   q[i] = len(words) - count\n",
        "\n",
        "\n",
        "# print(\"Number of parsed candidates \",len(parsed))\n",
        "# print(q, heapq.nlargest(3, q))\n",
        "\n",
        "\n",
        "candidates = itemgetter(*[0,7])(parsed)\n",
        "for _ in candidates:\n",
        "  words = _[0]\n",
        "  tagged = _[3]\n",
        "  print(\"tagged vector of candidates: \",tagged)\n",
        "  roles = _[2]\n",
        "  for i in range(len(tagged)):\n",
        "    try:\n",
        "      roles[i] = tagged[i].split(\"-\")[1]\n",
        "    except:\n",
        "      roles[i] = tagged[i].split(\"-\")[0]\n",
        "\n",
        "  print(words,f'\\nTagged words for the roles : ',roles)\n",
        "  print()\n",
        "# roles are selected as the one with effects only\n",
        "\n",
        "tagged = parsed[0][3]\n",
        "roles = parsed[0][2]\n",
        "for i in range(len(tagged)):\n",
        "    try:\n",
        "      roles[i] = tagged[i].split(\"-\")[1]\n",
        "    except:\n",
        "      roles[i] = tagged[i].split(\"-\")[0]\n",
        "\n",
        "print(words,'\\nTagged words for the roles : ',roles)  \n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "purpose = []\n",
        "instrument = []\n",
        "effects = []\n",
        "entity = []\n",
        "\n",
        "for _ in range(len(words)):\n",
        "  if roles[_]==\"Purpose\":\n",
        "    purpose.append(words[_])\n",
        "    \n",
        "  if roles[_]==\"Instrument\":\n",
        "    instrument.append(words[_])\n",
        "  \n",
        "  if roles[_]==\"Effect\":\n",
        "    effects.append(words[_])\n",
        "    \n",
        "  \n",
        "  if roles[_]==\"Entity\":\n",
        "    entity.append(words[_])\n",
        "    \n",
        "  elif roles[_]!=\"_\": # using í¬í•¨\n",
        "    instrument.append(words[_])\n",
        "print(\"Effects \",effects)\n",
        "\n",
        "\n",
        "# Effects\n",
        "EFFECT = ' '.join(effects)\n",
        "pos = h.pos(EFFECT)\n",
        "imp = []\n",
        "for tup in pos:\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "EFFECT_TRUNCATED = ' '.join(imp)\n",
        "print(EFFECT_TRUNCATED)\n",
        "\n",
        "final_string = EFFECT_TRUNCATED\n",
        "print(\"ğŸ˜€ final string to be inserted \", final_string)\n",
        "\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tagged vector of candidates:  ['O', 'O', 'B-Effect', 'I-Effect', 'I-Effect', 'I-Effect', 'I-Effect', 'I-Effect', 'I-Effect', 'I-Effect', 'I-Effect', 'I-Effect', 'I-Effect', 'I-Effect', 'I-Effect']\n",
            "['ê·¸', 'ê²°ê³¼', 'ì‚¬ìš©ìê°€', 'ìì—°ì–´ë¡œ', 'ì“°ì¸', 'ëŒ€ë³¸ì„', 'í…2í”¼ì—', 'ì œê³µí•˜ë©´', 'ë†’ì€', 'ìˆ˜ì¤€ì˜', 'í”¼í”¼í‹°ë¡œ', 'ì œê³µí• ', 'ìˆ˜', 'ìˆê²Œ', 'ë˜ì—ˆìŠµë‹ˆë‹¤.'] \n",
            "Tagged words for the roles :  ['O', 'O', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect']\n",
            "\n",
            "tagged vector of candidates:  ['O', 'O', 'B-Entity', 'I-Entity', 'I-Entity', 'I-Entity', 'I-Entity', 'I-Entity', 'I-Event', 'I-Entity', 'I-Entity', 'I-Entity', 'I-Entity', 'O', 'O']\n",
            "['ê·¸', 'ê²°ê³¼', 'ì‚¬ìš©ìê°€', 'ìì—°ì–´ë¡œ', 'ì“°ì¸', 'ëŒ€ë³¸ì„', 'í…2í”¼ì—', 'ì œê³µí•˜ë©´', 'ë†’ì€', 'ìˆ˜ì¤€ì˜', 'í”¼í”¼í‹°ë¡œ', 'ì œê³µí• ', 'ìˆ˜', 'ìˆê²Œ', 'ë˜ì—ˆìŠµë‹ˆë‹¤.'] \n",
            "Tagged words for the roles :  ['O', 'O', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', 'Entity', 'Event', 'Entity', 'Entity', 'Entity', 'Entity', 'O', 'O']\n",
            "\n",
            "['ê·¸', 'ê²°ê³¼', 'ì‚¬ìš©ìê°€', 'ìì—°ì–´ë¡œ', 'ì“°ì¸', 'ëŒ€ë³¸ì„', 'í…2í”¼ì—', 'ì œê³µí•˜ë©´', 'ë†’ì€', 'ìˆ˜ì¤€ì˜', 'í”¼í”¼í‹°ë¡œ', 'ì œê³µí• ', 'ìˆ˜', 'ìˆê²Œ', 'ë˜ì—ˆìŠµë‹ˆë‹¤.'] \n",
            "Tagged words for the roles :  ['O', 'O', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect', 'Effect']\n",
            "\n",
            "Effects  ['ì‚¬ìš©ìê°€', 'ìì—°ì–´ë¡œ', 'ì“°ì¸', 'ëŒ€ë³¸ì„', 'í…2í”¼ì—', 'ì œê³µí•˜ë©´', 'ë†’ì€', 'ìˆ˜ì¤€ì˜', 'í”¼í”¼í‹°ë¡œ', 'ì œê³µí• ', 'ìˆ˜', 'ìˆê²Œ', 'ë˜ì—ˆìŠµë‹ˆë‹¤.']\n",
            "ì‚¬ìš©ì ìì—°ì–´ ëŒ€ë³¸ í…2í”¼ ì œê³µ ìˆ˜ì¤€ í”¼í”¼í‹° ì œê³µ ìˆ˜\n",
            "ğŸ˜€ final string to be inserted  ì‚¬ìš©ì ìì—°ì–´ ëŒ€ë³¸ í…2í”¼ ì œê³µ ìˆ˜ì¤€ í”¼í”¼í‹° ì œê³µ ìˆ˜\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNd6i5V2H09W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slide_1.placeholders.element[18][2][2][1][1].text = \"í°íŠ¸, í…œí”Œë¦¿, ë²¡í„° ì´ë¯¸ì§€ ë“±ì„ ë³´ê¸°ì‰¬ìš´ ì¸í„°í˜ì´ìŠ¤ë¡œ ì¶”ì²œ\" # ë‘ ë²ˆì§¸ ì„¤ëª…\n",
        "slide_1.placeholders.element[19][2][2][1][1].text = \"ì–‘ì§ˆì˜ ë°œí‘œë¥¼ ìœ„í•´ ë‚´ìš©ì˜ ê·¼ê±°ê°€ ë  ìˆ˜ ìˆëŠ” chartì™€ table ê·¸ë¦¬ê³  image ì¶”ì²œ ì‹œìŠ¤í…œ\" # ì„¸ ë²ˆì§¸ ì„¤ëª…\n",
        "prs.save('test1.pptx')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}

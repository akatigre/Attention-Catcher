{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutomatedRelationExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonkim313/dataCampusProject-Team10/blob/master/Relation%20Extraction/5.AutomatedRelationExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "id": "obGBWFLnIypX",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa400519-3647-4a00-e483-ad4a47ffa08d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install transformers\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy\n",
        "!pip install kss\n",
        "%cd /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
        "!pip install soykeyword\n",
        "from frameBERT import frame_parser\n",
        "path=\"/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778kB 5.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 30.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 24.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 35.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=049b1a6f7c9150629e0e72a9ff984cd502719d2a6faca365a9e8944bb592d293\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Ign:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [255 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [890 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [9,834 B]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,043 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [101 kB]\n",
            "Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,857 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [27.4 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [117 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,341 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,417 kB]\n",
            "Get:24 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [896 kB]\n",
            "Fetched 8,227 kB in 4s (2,224 kB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MbmSXGrwJ585",
        "colab": {}
      },
      "source": [
        "import kss\n",
        "from konlpy.tag import Hannanum, Okt\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import heapq\n",
        "import pandas as pd\n",
        "from operator import itemgetter\n",
        "from collections import deque\n",
        "from ast import literal_eval\n",
        "from collections import defaultdict\n",
        "from soykeyword.lasso import LassoKeywordExtractor\n",
        "from pprint import pprint\n",
        "!pip install krwordrank\n",
        "from krwordrank.word import KRWordRank\n",
        "from copy import deepcopy\n",
        "h = Hannanum()\n",
        "okt = Okt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_v5o0el7I9ur",
        "colab": {}
      },
      "source": [
        "text = '''\n",
        "í‰ë“±ì€ ììœ ì™€ ë”ë¶ˆì–´ ê·¼ëŒ€ ì‚¬íšŒì˜ í•µì‹¬ ì´ë…ìœ¼ë¡œ ìë¦¬ ì¡ê³ ìˆë‹¤. ì¸ê°„ì€ ê°€ë ¹ ì¸ì¢…ì´ë‚˜ ì„±ë³„ê³¼ ìƒê´€ì—†ì´ ëˆ„êµ¬ë‚˜ í‰ë“±í•˜ë‹¤ê³  ìƒê°í•œë‹¤. ëª¨ë“  ì¸ê°„ì€ í‰ë“±í•˜ë‹¤ê³  ë§í•˜ëŠ”ë°, ì´ ë§ì€ ë¬´ìŠ¨ ëœ»ì¼ê¹Œ? ê·¸ë¦¬ê³  ê·¸ ê·¼ê±°ëŠ” ë¬´ì—‡ì¸ê°€? \n",
        "ì¼ë‹¨ ì´ ë§ì„ ëª¨ë“  ì¸ê°„ì„ ëª¨ë“  ì¸¡ë©´ì—ì„œ ë˜‘ê°™ì´ ëŒ€ìš°í•˜ëŠ” ì ˆëŒ€ì¹™ í‰ë“±ìœ¼ë¡œ ìƒê°í•˜ëŠ” ì´ëŠ” ì—†ë‹¤. ì¸ê°„ì€ ì €ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ê°€ì§€ê³  ëŒ€ì–´ë‚œ ëŠ¥ë ¥ê³¼ ì†Œì§ˆì„ ë˜‘ê°™ê²Œ ë§Œë“¤ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì´ë‹¤. ì ˆëŒ€ì  í‰ë“±ì€ ê°œì¸ì˜ ê°œì„±ì´ëƒ ììœ¨ì„± ë“±ì˜ ê°€ì¹˜ì™€ ì¶©ëŒí•˜ê¸°ë„ í•œë‹¤. í‰ë“±ì— ëŒ€í•œ ìš”êµ¬ëŠ” ëª¨ë“  ë¶ˆí‰ë“±ì„ ì•…ìœ¼ë¡œ ë³´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì¶©ë¶„í•œ ì´ìœ ê°€ ì œì‹œë˜ì§€ ì•Šì€ ë¶ˆí‰ë“±ì„ ì œê±°í•˜ëŠ” ë° ëª©í‘œë¥¼ ë‘ê³  ìˆë‹¤. â€˜ì´ìœ  ì—†ëŠ” ì°¨ë³„ ê¸ˆì§€â€™ë¼ëŠ” ì¡°ê±´ì  í‰ë“± ì›ì¹™ì€ ì°¨ë³„ ëŒ€ìš°ë¥¼ í•  ë•ŒëŠ” ì´ìœ ë¥¼ ì œì‹œí•  ê²ƒì„ ìš”êµ¬í•˜ê³  ìˆë‹¤. ì´ê²ƒì€ ì–´ë–¤ ì´ìœ ê°€ ì œì‹œëœë‹¤ë©´ íŠ¹ì •í•œ ë¶€ë¥˜ì— ì†í•˜ëŠ” ì‚¬ëŒë“¤ì—ê²ŒëŠ” í‰ë“±í•œ ëŒ€ìš°ë¥¼, ê·¸ ë¶€ë¥˜ì— ì†í•˜ì§€ ì•ŠëŠ” ì‚¬ëŒë“¤ì—ê²ŒëŠ” ì°¨ë³„ì € ëŒ€ìš°ë¥¼ í•˜ëŠ” ê²ƒì„ í—ˆìš©í•œë‹¤. ê·¸ë ‡ë‹¤ë©´ ì‚¬ëŒë“¤ì„ íŠ¹ì •í•œ ë¶€ë¥˜ë¡œ êµ¬ë¶„í•˜ëŠ” ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€? ì´ê²ƒì€ ë°”ë¡œ í‰ë“±ì˜ ê·¼ê±°ì— ëŒ€í•œ ë¬¼ìŒì´ë‹¤.\n",
        "ê·¼ëŒ€ì˜ ì—¬ëŸ¬ ì¸ê¶Œ ì„ ì–¸ì— ë‚˜íƒ€ë‚œ í‰ë“± ê°œë…ì€ ê°œì¸ë“¤ ì‚¬ì´ì˜ í‰ë“±ì„±ì„ íƒ€ê³ ë‚œ ìì—°ì  ê¶Œë¦¬ë¡œ ê°„ì£¼í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ ì´ëŸ¬í•œ ìì—°ê¶Œ ì´ë¡ ì€ ë¬´ì—‡ì´ ìì—°ì  ê¶Œë¦¬ì´ê³  ê¶Œë¦¬ì˜ ì¡´ì¬ê°€ ìëª…í•œ ì´ìœ ê°€ ë¬´ì—‡ì¸ì§€ ë“±ì˜ ë¬¸ì œì— ë¶€ë”ªíˆê²Œ ëœë‹¤. ê·¸ë˜ì„œ ë¡¤ìŠ¤ëŠ” ê¸°ì¡´ì˜ ìì—°ê¶Œ ì‚¬ìƒì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ” ë°©ì‹œìœ¼ë¡œ ì¸ê°„ í‰ë“±ì˜ ê·¼ê±°ë¥¼ ë§ˆëŸ°í•˜ë ¤ê³  í•œë‹¤. ê·¸ëŠ” ì–´ë–¤ ê·œì¹™ì´ ê³µí‰í•˜ê³  ì¼ê´€ë˜ê²Œ ìš´ì˜ë˜ë©°, ê·¸ ê·œì¹™ì— ë”°ë¼ ìœ ì‚¬í•œ ê²½ìš°ëŠ” ìœ ì‚¬í•˜ê²Œ ì·¨ê¸‰ëœë‹¤ë©´ í˜•ì‹ì  ì •ì˜ëŠ” ì‹¤í˜„ëœë‹¤ê³  ë³¸ë‹¤. í•˜ì§€ë§Œ ë¡¤ìŠ¤ëŠ” í˜•ì‹ì € ì •ì˜ì— ë”°ë¼ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì •ì˜ë¥¼ ë‹´ë³´í•  ìˆ˜ ì—†ë‹¤ê³  ìƒê°í•œë‹¤. ê·¸ ê·œì¹™ì´ ë” ë†’ì€ ë„ë•ì  ê¶Œìœ„ë¥¼ ì§€ë‹Œ ë‹¤ë¥¸ ì´ë„˜ê³¼ ì¶©ëŒí•  ìˆ˜ ì—ˆê¸°ì—, ì‹¤ì§ˆì  ì •ì˜ê°€ ë³´ì¥ë˜ê¸° ìœ„í•´ì„œëŠ” ê·œì¹™ì˜ ë‚´ìš©ì´ ì¤‘ìš”í•œ ê²ƒì´ë‹¤.\n",
        "ë¡¤ìŠ¤ëŠ” ì¸ê°„ í‰ë“±ì˜ ê·¼ê±°ë¥¼ ì„¤ëª…í•˜ë©´ì„œ ì˜ì—­ ì„±ì§ˆ (range property) ê°œë…ì„ ë„ì…í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì–´ë–¤ ì›ì˜ ë‚´ë¶€ì— ìˆëŠ” ì ë“¤ì€ ê·¸ ìœ„ì¹˜ê°€ ì„œë¡œ ë‹¤ë¥´ì§€ë§Œ ì›ì˜ ë‚´ë¶€ì— ìˆë‹¤ëŠ” ì ì—ì„œ ë™ì¼í•œ ì˜ì—­ ì„±ì§ˆì„ ê°–ëŠ”ë‹¤. ë°˜ë©´ì— ì›ì˜ ë‚´ë¶€ì— ìˆëŠ” ì§‘ê³¼ ì›ì˜ ì™¸ë¶€ì— ì˜€ëŠ” ì ì€ì›ì˜ ê²½ê³„ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ ì„œë¡œ ë‹¤ë¥¸ ì˜ì—­ ì„±ì§ˆì„ ê°–ëŠ”ë‹¤. ê·¸ëŠ” í‰ë“±í•œ ëŒ€ìš°ë¥¼ ë°›ê¸° ìœ„í•œ ì˜ì—­ ì„±ì§ˆë¡œì„œ â€˜ë„ë•ì  ì¸ê²©'ì„ ì œì‹œí•œë‹¤. ë„ë•ì  ì¸ê²©ì´ë€ ë„ë•ì  í˜¸ì†Œê°€ ê°€ëŠ¥í•˜ê³  ê·¸ëŸ° í˜¸ì†Œì— ê´€ì‹¬ì„ ê¸°ì´ëŠ” ëŠ¥ë ¥ì´ ìˆë‹¤ëŠ” ê²ƒì¸ë°, ì´ ëŠ¥ë ¥ì„ ìµœì†Œì¹˜ë§Œ ê°–ê³  ìˆë‹¤ë©´ í‰ë“±í•œ ëŒ€ìš°ì— ëŒ€í•œ ê¶Œí•œì„ ê°–ê²Œ ëœë‹¤. ë„ë•ì  ì¸ê²©ì´ë¼ê³  í•´ì„œ ë„ë•ì ìœ¼ë¡œ í›Œë¥­í•˜ë‹¤ëŠ” ëœ»ì´ ì•„ë‹ˆë¼ ë„ë•ê³¼ ë¬´ê´€í•˜ë‹¤ëŠ” ë§ê³¼ ëŒ€ë¹„ë˜ëŠ” ëœ»ìœ¼ë¡œ ì“°ê³  ìˆë‹¤. ê·¸ëŸ°ë° ì–´ë¦° ì•„ì´ëŠ” ì¸ê²©ì²´ë¡œì„œì˜ ìµœì†Œí•œì˜ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ê³  ìˆëŠ”ì§€ê°€ ë…¼ë€ì´ ë  ìˆ˜ ìˆë‹¤. ì´ì— ëŒ€í•´ ë¡¤ìŠ¤ëŠ” ë„ë•ì  ì¸ê²©ì„ ê·œì •í•˜ëŠ” ìµœì†Œí•œì˜ ìš”êµ¬ ì¡°ê±´ì€ ì ì¬ì  ëŠ¥ë ¥ì´ì§€ ê·¸ê²ƒì˜ ì‹¤í˜„ ì—¬ë¶€ê°€ ì•„ë‹ˆê¸°ì— ì–´ë¦° ì•„ì´ë„ í‰ë“±í•œ ì¡´ì¬ë¼ê³  ë§í•œë‹¤. ì‹±ì–´ëŠ” ìœ„ì™€ ê°™ì€ ë¡¤ìŠ¤ì˜ ì‹œë„ë¥¼ ë¹„íŒí•œë‹¤. ë„ë•ì— ëŒ€í•œ ë¯¼ê°ì„±ì˜ ìˆ˜ì¤€ì€ ì‚¬ëŒì— ë”°ë¼ ë‹¤ë¥´ë‹¤. ê·¸ë˜ì„œ ë„ë•ì  ì¸ê²©ì˜ ëŠ¥ë ¥ì´ ê·¸ë ‡ê²Œ ì¤‘ìš”í•˜ë‹¤ë©´ ê·¸ê²ƒì„ ê°–ì¶˜ ì •ë„ì— ë”°ë¼ ë„ë•ì  ìœ„ê³„ë¥¼ ë‹¤ë¥´ê²Œ í•˜ì§€ ë§ì•„ì•¼ í•  ì´ìœ ê°€ ë¶„ëª…í•˜ì§€ ì•Šë‹¤ê³  ë§í•œë‹¤. \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGCJPBUtvXj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "b18556c7-9124-4271-d82b-a790f8d1a00a"
      },
      "source": [
        "class Text:\n",
        "  def __init__(self, text):\n",
        "    self.text = text\n",
        "    text = re.sub('\\n',' ',text)\n",
        "    text = re.sub(\"'\",' ',text)\n",
        "    paragraphs = text.split('\\n')\n",
        "    self.docs = [kss.split_sentences(paragraph) for paragraph in paragraphs]\n",
        "\n",
        "  def add_tags(self, tag):\n",
        "    \n",
        "    for i in range(len(self.idx)):\n",
        "      idx = [(self.newtext.find(\" \"+cand), len(cand)) for cand in self.candidates if self.newtext.find(cand)!=-1]\n",
        "      print(idx)\n",
        "      indices = (idx[i][0],idx[i][0]+idx[i][1]+1)\n",
        "      word = self.newtext[indices[0]+1:indices[1]]\n",
        "      print(word)\n",
        "      tagged = \"<%s>%s</%s>\" % (tag, word, tag)\n",
        "      print(tagged)\n",
        "      self.newtext = tagged.join([self.newtext[:indices[0]], self.newtext[indices[1]:]])\n",
        "    return self.newtext\n",
        "\n",
        "  def keywords(self):\n",
        "    wordrank_extractor = KRWordRank(min_count=4, max_length=10)\n",
        "    keywords, rank, graph = wordrank_extractor.extract(documents, num_keywords=50)\n",
        "    p=[]\n",
        "    kw=[]\n",
        "    for k, v in keywords.items():\n",
        "      p.append(okt.pos(k))\n",
        "    for ls in p:\n",
        "      for tup in ls:\n",
        "          print(tup[0],tup[1])\n",
        "          if tup[1].startswith(\"N\"):\n",
        "            kw.append(tup[0])\n",
        "    return kw\n",
        "    conj_tag = \"conj\"  # html ë§Œë“¤ ë–„ mark ë¶€ë¶„ì„ conjë¡œ ë³€ê²½í•˜ê¸°\n",
        "\n",
        "class Highlight(Text):\n",
        "  def __init__(self, text):\n",
        "    conj = 'ê·¸ë¦¬ê³ , ê·¸ëŸ°ë°, ê·¸ëŸ¬ë‚˜, ê·¸ë˜ë„, ê·¸ë˜ì„œ, ë˜ëŠ”, ë°, ì¦‰, ê²Œë‹¤ê°€, ë”°ë¼ì„œ, ë•Œë¬¸ì—, ì•„ë‹ˆë©´, ì™œëƒí•˜ë©´, ë‹¨, ì˜¤íˆë ¤, ë¹„ë¡'\n",
        "    conj = conj.replace(\"'\",\"\")\n",
        "    conj = conj.replace(\", \",\" \")\n",
        "    self.text = text\n",
        "    self.candidates = conj.split(\" \")\n",
        "    self.idx = [(self.text.find(\" \"+cand), len(cand)) for cand in self.candidates if self.text.find(cand)!=-1]\n",
        "    self.newtext = deepcopy(self.text)\n",
        "\n",
        "\n",
        "c.add_tags(conj_tag)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ë„ë• Noun\n",
            "ì  Suffix\n",
            "í‰ë“± Noun\n",
            "ì¸ê°„ Noun\n",
            "ì´ìœ  Noun\n",
            "ê°€ Josa\n",
            "ëŠ¥ë ¥ Noun\n",
            "ë”°ë¼ Verb\n",
            "ìˆë‹¤ Adjective\n",
            ". Punctuation\n",
            "ì–´ë–¤ Adjective\n",
            "ì˜ì—­ Noun\n",
            "ëŒ€ìš° Noun\n",
            "ê·¼ê±° Noun\n",
            "ë¡¤ìŠ¤ Noun\n",
            "ëŠ” Josa\n",
            "ëª¨ë“  Noun\n",
            "ì› Noun\n",
            "ì˜ Josa\n",
            "ê·œì¹™ Noun\n",
            "ì¡´ì¬ Noun\n",
            "ì¸ê²© Noun\n",
            "ìˆëŠ” Adjective\n",
            "ì„±ì§ˆ Noun\n",
            "ë‹¤ë¥´ Adjective\n",
            "ëŒ€í•œ Noun\n",
            "ê¶Œë¦¬ Noun\n",
            "ì œì‹œ Noun\n",
            "ì •ì˜ Noun\n",
            "ë¬´ì—‡ Noun\n",
            "ìì—° Noun\n",
            "ìµœì†Œ Noun\n",
            "ì‚¬ëŒ Noun\n",
            "['ë„ë•', 'í‰ë“±', 'ì¸ê°„', 'ì´ìœ ', 'ëŠ¥ë ¥', 'ì˜ì—­', 'ëŒ€ìš°', 'ê·¼ê±°', 'ë¡¤ìŠ¤', 'ëª¨ë“ ', 'ì›', 'ê·œì¹™', 'ì¡´ì¬', 'ì¸ê²©', 'ì„±ì§ˆ', 'ëŒ€í•œ', 'ê¶Œë¦¬', 'ì œì‹œ', 'ì •ì˜', 'ë¬´ì—‡', 'ìì—°', 'ìµœì†Œ', 'ì‚¬ëŒ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYz2ZMyKyASO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  t = Text(text)\n",
        "  print(t.keywords())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft2LfkPlZhK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "ea8d39a2-a36d-4a6a-b8cd-6c8cc74b58f2"
      },
      "source": [
        "pprint(okt.tagset)\n",
        "print()\n",
        "pprint(h.tagset)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Adjective': 'í˜•ìš©ì‚¬',\n",
            " 'Adverb': 'ë¶€ì‚¬',\n",
            " 'Alpha': 'ì•ŒíŒŒë²³',\n",
            " 'Conjunction': 'ì ‘ì†ì‚¬',\n",
            " 'Determiner': 'ê´€í˜•ì‚¬',\n",
            " 'Eomi': 'ì–´ë¯¸',\n",
            " 'Exclamation': 'ê°íƒ„ì‚¬',\n",
            " 'Foreign': 'ì™¸êµ­ì–´, í•œì ë° ê¸°íƒ€ê¸°í˜¸',\n",
            " 'Hashtag': 'íŠ¸ìœ„í„° í•´ì‰¬íƒœê·¸',\n",
            " 'Josa': 'ì¡°ì‚¬',\n",
            " 'KoreanParticle': '(ex: ã…‹ã…‹)',\n",
            " 'Noun': 'ëª…ì‚¬',\n",
            " 'Number': 'ìˆ«ì',\n",
            " 'PreEomi': 'ì„ ì–´ë§ì–´ë¯¸',\n",
            " 'Punctuation': 'êµ¬ë‘ì ',\n",
            " 'ScreenName': 'íŠ¸ìœ„í„° ì•„ì´ë””',\n",
            " 'Suffix': 'ì ‘ë¯¸ì‚¬',\n",
            " 'Unknown': 'ë¯¸ë“±ë¡ì–´',\n",
            " 'Verb': 'ë™ì‚¬'}\n",
            "\n",
            "{'E': 'ì–´ë¯¸',\n",
            " 'EC': 'ì—°ê²° ì–´ë¯¸',\n",
            " 'EF': 'ì¢…ê²° ì–´ë¯¸',\n",
            " 'EP': 'ì„ ì–´ë§ì–´ë¯¸',\n",
            " 'ET': 'ì „ì„± ì–´ë¯¸',\n",
            " 'F': 'ì™¸êµ­ì–´',\n",
            " 'I': 'ë…ë¦½ì–¸',\n",
            " 'II': 'ê°íƒ„ì‚¬',\n",
            " 'J': 'ê´€ê³„ì–¸',\n",
            " 'JC': 'ê²©ì¡°ì‚¬',\n",
            " 'JP': 'ì„œìˆ ê²© ì¡°ì‚¬',\n",
            " 'JX': 'ë³´ì¡°ì‚¬',\n",
            " 'M': 'ìˆ˜ì‹ì–¸',\n",
            " 'MA': 'ë¶€ì‚¬',\n",
            " 'MM': 'ê´€í˜•ì‚¬',\n",
            " 'N': 'ì²´ì–¸',\n",
            " 'NB': 'ì˜ì¡´ëª…ì‚¬',\n",
            " 'NC': 'ë³´í†µëª…ì‚¬',\n",
            " 'NN': 'ìˆ˜ì‚¬',\n",
            " 'NP': 'ëŒ€ëª…ì‚¬',\n",
            " 'NQ': 'ê³ ìœ ëª…ì‚¬',\n",
            " 'P': 'ìš©ì–¸',\n",
            " 'PA': 'í˜•ìš©ì‚¬',\n",
            " 'PV': 'ë™ì‚¬',\n",
            " 'PX': 'ë³´ì¡° ìš©ì–¸',\n",
            " 'S': 'ê¸°í˜¸',\n",
            " 'X': 'ì ‘ì‚¬',\n",
            " 'XP': 'ì ‘ë‘ì‚¬',\n",
            " 'XS': 'ì ‘ë¯¸ì‚¬'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA8bpjMZbtnM",
        "colab_type": "text"
      },
      "source": [
        "#### í•˜ì§€ë§Œ, ê·¸ëŸ°ë° ë“±ì˜ ì—°ê²°ì‚¬ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ ì¶”ì¶œ\n",
        "\n",
        "css ë¬¸ë²•\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "mark { \n",
        "  background-color: yellow;\n",
        "  color: black;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<p>A mark element is displayed like this:</p>\n",
        "\n",
        "<mark>Highlighted text!!</mark>\n",
        "\n",
        "<p>Change the default CSS settings to see the effect.</p>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJzpR_hodGVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3059eedd-7bf7-48ff-ed13-15b67286c180"
      },
      "source": [
        "conj = 'ê·¸ë¦¬ê³ , ê·¸ëŸ°ë°, ê·¸ëŸ¬ë‚˜, ê·¸ë˜ë„, ê·¸ë˜ì„œ, ë˜ëŠ”, ë°, ì¦‰, ê²Œë‹¤ê°€, ë”°ë¼ì„œ, ë•Œë¬¸ì—, ì•„ë‹ˆë©´, ì™œëƒí•˜ë©´, ë‹¨, ì˜¤íˆë ¤, ë¹„ë¡'\n",
        "conj = conj.replace(\"'\",\"\")\n",
        "conj = conj.replace(\", \",\" \")\n",
        "candidates = conj.split(\" \")\n",
        "print(candidates)\n",
        "idx = [(text.find(cand), len(cand)) for cand in candidates if text.find(cand)!=-1]\n",
        "print(idx)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ê·¸ë¦¬ê³ ', 'ê·¸ëŸ°ë°', 'ê·¸ëŸ¬ë‚˜', 'ê·¸ë˜ë„', 'ê·¸ë˜ì„œ', 'ë˜ëŠ”', 'ë°', 'ì¦‰', 'ê²Œë‹¤ê°€', 'ë”°ë¼ì„œ', 'ë•Œë¬¸ì—', 'ì•„ë‹ˆë©´', 'ì™œëƒí•˜ë©´', 'ë‹¨', 'ì˜¤íˆë ¤', 'ë¹„ë¡']\n",
            "[(107, 3), (1292, 3), (656, 3), (1766, 1), (1850, 3), (124, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgDrUAoAhWWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "outputId": "43268bbe-aef9-417a-b104-bec1e646c3bf"
      },
      "source": [
        "conj_tag = \"conj\"  # html ë§Œë“¤ ë–„ mark ë¶€ë¶„ì„ conjë¡œ ë³€ê²½í•˜ê¸°\n",
        "\n",
        "class Highlight:\n",
        "  def __init__(self, text):\n",
        "    conj = 'ê·¸ë¦¬ê³ , ê·¸ëŸ°ë°, ê·¸ëŸ¬ë‚˜, ê·¸ë˜ë„, ê·¸ë˜ì„œ, ë˜ëŠ”, ë°, ì¦‰, ê²Œë‹¤ê°€, ë”°ë¼ì„œ, ë•Œë¬¸ì—, ì•„ë‹ˆë©´, ì™œëƒí•˜ë©´, ë‹¨, ì˜¤íˆë ¤, ë¹„ë¡'\n",
        "    conj = conj.replace(\"'\",\"\")\n",
        "    conj = conj.replace(\", \",\" \")\n",
        "    self.text = text\n",
        "    self.candidates = conj.split(\" \")\n",
        "    self.idx = [(self.text.find(\" \"+cand), len(cand)) for cand in self.candidates if self.text.find(cand)!=-1]\n",
        "    self.newtext = deepcopy(self.text)\n",
        "\n",
        "  def add_tags(self, tag):\n",
        "    \n",
        "    for i in range(len(self.idx)):\n",
        "      idx = [(self.newtext.find(\" \"+cand), len(cand)) for cand in self.candidates if self.newtext.find(cand)!=-1]\n",
        "      print(idx)\n",
        "      indices = (idx[i][0],idx[i][0]+idx[i][1]+1)\n",
        "      word = self.newtext[indices[0]+1:indices[1]]\n",
        "      print(word)\n",
        "      tagged = \"<%s>%s</%s>\" % (tag, word, tag)\n",
        "      print(tagged)\n",
        "      self.newtext = tagged.join([self.newtext[:indices[0]], self.newtext[indices[1]:]])\n",
        "    return self.newtext\n",
        "\n",
        "c = Highlight(text)\n",
        "c.add_tags(conj_tag)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(106, 3), (1291, 3), (655, 3), (1765, 1), (1849, 3), (-1, 1)]\n",
            "ê·¸ë¦¬ê³ \n",
            "<conj>ê·¸ë¦¬ê³ </conj>\n",
            "[(1564, 3), (1303, 3), (667, 3), (1777, 1), (1861, 3), (-1, 1)]\n",
            "ê·¸ëŸ°ë°\n",
            "<conj>ê·¸ëŸ°ë°</conj>\n",
            "[(1576, 3), (-1, 3), (667, 3), (1789, 1), (1873, 3), (-1, 1)]\n",
            "ê·¸ë˜ì„œ\n",
            "<conj>ê·¸ë˜ì„œ</conj>\n",
            "[(1588, 3), (-1, 3), (1509, 3), (1801, 1), (1885, 3), (-1, 1)]\n",
            "ì¦‰\n",
            "<conj>ì¦‰</conj>\n",
            "[(1588, 3), (-1, 3), (1509, 3), (-1, 1), (1897, 3), (-1, 1)]\n",
            "ë•Œë¬¸ì—\n",
            "<conj>ë•Œë¬¸ì—</conj>\n",
            "[(1588, 3), (-1, 3), (1509, 3), (-1, 1), (2004, 3), (-1, 1)]\n",
            " \n",
            "<conj> </conj>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' í‰ë“±ì€ ììœ ì™€ ë”ë¶ˆì–´ ê·¼ëŒ€ ì‚¬íšŒì˜ í•µì‹¬ ì´ë…ìœ¼ë¡œ ìë¦¬ ì¡ê³  ìˆë‹¤. ì¸ê°„ì€ ê°€ë ¹ ì¸ì¢…ì´ë‚˜ ì„±ë³„ê³¼ ìƒê´€ì—†ì´ ëˆ„êµ¬ë‚˜ í‰ë“±í•˜ë‹¤ê³  ìƒê°í•œë‹¤. ëª¨ë“  ì¸ê°„ì€ í‰ë“±í•˜ë‹¤ê³  ë§í•˜ëŠ”ë°, ì´ ë§ì€ ë¬´ìŠ¨ ëœ»ì¼ê¹Œ?<conj>ê·¸ë¦¬ê³ </conj> ê·¸ ê·¼ê±°ëŠ” ë¬´ì—‡ì¸ê°€? ì¼ë‹¨ ì´ ë§ì„ ëª¨ë“  ì¸ê°„ì„ ëª¨ë“  ì¸¡ë©´ì—ì„œ ë˜‘ê°™ì´ ëŒ€ìš°í•˜ëŠ” ì ˆëŒ€ì¹™ í‰ë“±ìœ¼ë¡œ ìƒê°í•˜ëŠ” ì´ëŠ” ì—†ë‹¤. ì¸ê°„ì€ ì €ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ê°€ì§€ê³  ëŒ€ì–´ë‚œ ëŠ¥ë ¥ê³¼ ì†Œì§ˆì„ ë˜‘ê°™ê²Œ ë§Œë“¤ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì´ë‹¤. ì ˆëŒ€ì  í‰ë“±ì€ ê°œì¸ì˜ ê°œì„±ì´ëƒ ììœ¨ì„± ë“±ì˜ ê°€ì¹˜ì™€ ì¶©ëŒí•˜ê¸°ë„ í•œë‹¤. í‰ë“±ì— ëŒ€í•œ ìš”êµ¬ëŠ” ëª¨ë“  ë¶ˆí‰ë“±ì„ ì•…ìœ¼ë¡œ ë³´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì¶©ë¶„í•œ ì´ìœ ê°€ ì œì‹œë˜ì§€ ì•Šì€ ë¶ˆí‰ë“±ì„ ì œê±°í•˜ëŠ” ë° ëª©í‘œë¥¼ ë‘ê³  ìˆë‹¤. â€˜ì´ìœ  ì—†ëŠ” ì°¨ë³„ ê¸ˆì§€â€™ë¼ëŠ” ì¡°ê±´ì  í‰ë“± ì›ì¹™ì€ ì°¨ë³„ ëŒ€ìš°ë¥¼ í•  ë•ŒëŠ” ì´ìœ ë¥¼ ì œì‹œí•  ê²ƒì„ ìš”êµ¬í•˜ê³  ìˆë‹¤. ì´ê²ƒì€ ì–´ë–¤ ì´ìœ ê°€ ì œì‹œëœë‹¤ë©´ íŠ¹ì •í•œ ë¶€ë¥˜ì— ì†í•˜ëŠ” ì‚¬ëŒë“¤ì—ê²ŒëŠ” í‰ë“±í•œ ëŒ€ìš°ë¥¼, ê·¸ ë¶€ë¥˜ì— ì†í•˜ì§€ ì•ŠëŠ” ì‚¬ëŒë“¤ì—ê²ŒëŠ” ì°¨ë³„ì € ëŒ€ìš°ë¥¼ í•˜ëŠ” ê²ƒì„ í—ˆìš©í•œë‹¤. ê·¸ë ‡ë‹¤ë©´ ì‚¬ëŒë“¤ì„ íŠ¹ì •í•œ ë¶€ë¥˜ë¡œ êµ¬ë¶„í•˜ëŠ” ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€? ì´ê²ƒì€ ë°”ë¡œ í‰ë“±ì˜ ê·¼ê±°ì— ëŒ€í•œ ë¬¼ìŒì´ë‹¤. ê·¼ëŒ€ì˜ ì—¬ëŸ¬ ì¸ê¶Œ ì„ ì–¸ì— ë‚˜íƒ€ë‚œ í‰ë“± ê°œë…ì€ ê°œì¸ë“¤ ì‚¬ì´ì˜ í‰ë“±ì„±ì„ íƒ€ê³ ë‚œ ìì—°ì  ê¶Œë¦¬ë¡œ ê°„ì£¼í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ ì´ëŸ¬í•œ ìì—°ê¶Œ ì´ë¡ ì€ ë¬´ì—‡ì´ ìì—°ì  ê¶Œë¦¬ì´ê³  ê¶Œë¦¬ì˜ ì¡´ì¬ê°€ ìëª…í•œ ì´ìœ ê°€ ë¬´ì—‡ì¸ì§€ ë“±ì˜ ë¬¸ì œì— ë¶€ë”ªíˆê²Œ ëœë‹¤.<conj>ê·¸ë˜ì„œ</conj> ë¡¤ìŠ¤ëŠ” ê¸°ì¡´ì˜ ìì—°ê¶Œ ì‚¬ìƒì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ” ë°©ì‹œìœ¼ë¡œ ì¸ê°„ í‰ë“±ì˜ ê·¼ê±°ë¥¼ ë§ˆëŸ° í•˜ë ¤ê³  í•œë‹¤. ê·¸ëŠ” ì–´ë–¤ ê·œì¹™ì´ ê³µí‰í•˜ê³  ì¼ê´€ë˜ê²Œ ìš´ì˜ë˜ë©°, ê·¸ ê·œì¹™ì— ë”°ë¼ ìœ ì‚¬í•œ ê²½ìš°ëŠ” ìœ ì‚¬í•˜ê²Œ ì·¨ê¸‰ëœë‹¤ë©´ í˜•ì‹ì  ì •ì˜ëŠ” ì‹¤í˜„ëœë‹¤ê³  ë³¸ë‹¤. í•˜ì§€ë§Œ ë¡¤ìŠ¤ëŠ” í˜•ì‹ì € ì •ì˜ì— ë”°ë¼ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì •ì˜ë¥¼ ë‹´ë³´í•  ìˆ˜ ì—†ë‹¤ê³  ìƒê°í•œë‹¤. ê·¸ ê·œì¹™ì´ ë” ë†’ì€ ë„ë•ì  ê¶Œìœ„ë¥¼ ì§€ë‹Œ ë‹¤ë¥¸ ì´ë„˜ê³¼ ì¶©ëŒí•  ìˆ˜ ì—ˆê¸°ì—, ì‹¤ì§ˆì  ì •ì˜ê°€ ë³´ì¥ë˜ê¸° ìœ„í•´ì„œëŠ” ê·œì¹™ì˜ ë‚´ìš©ì´ ì¤‘ìš”í•œ ê²ƒì´ë‹¤. ë¡¤ìŠ¤ëŠ” ì¸ê°„ í‰ë“±ì˜ ê·¼ê±°ë¥¼ ì„¤ëª…í•˜ë©´ì„œ ì˜ì—­ ì„±ì§ˆ (range property) ê°œë…ì„ ë„ì…í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì–´ë–¤ ì›ì˜ ë‚´ë¶€ì— ìˆëŠ” ì ë“¤ì€ ê·¸ ìœ„ ì¹˜ê°€ ì„œë¡œ ë‹¤ë¥´ì§€ë§Œ ì›ì˜ ë‚´ë¶€ì— ìˆë‹¤ëŠ” ì ì—ì„œ ë™ì¼í•œ ì˜ì—­ ì„±ì§ˆ ì„ ê°–ëŠ”ë‹¤. ë°˜ë©´ì— ì›ì˜ ë‚´ë¶€ì— ìˆëŠ” ì§‘ê³¼ ì›ì˜ ì™¸ë¶€ì— ì˜€ëŠ” ì ì€ ì›ì˜ ê²½ê³„ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ ì„œë¡œ ë‹¤ë¥¸ ì˜ì—­ ì„±ì§ˆì„ ê°–ëŠ”ë‹¤. ê·¸ëŠ” í‰ë“± í•œ ëŒ€ìš°ë¥¼ ë°›ê¸° ìœ„í•œ ì˜ì—­ ì„±ì§ˆë¡œì„œ â€˜ë„ë•ì  ì¸ê²© ì„ ì œì‹œí•œë‹¤. ë„ë•ì  ì¸ê²©ì´ë€ ë„ë•ì  í˜¸ì†Œê°€ ê°€ëŠ¥í•˜ê³  ê·¸ëŸ° í˜¸ì†Œì— ê´€ì‹¬ì„ ê¸°ìš¸ ì´ëŠ” ëŠ¥ë ¥ì´ ìˆë‹¤ëŠ” ê²ƒì¸ë°, ì´ ëŠ¥ë ¥ì„ ìµœì†Œì¹˜ë§Œ ê°–ê³  ìˆë‹¤ë©´ í‰ë“±í•œ ëŒ€ìš°ì— ëŒ€í•œ ê¶Œí•œì„ ê°–ê²Œ ëœë‹¤. ë„ë•ì  ì¸ê²©ì´ë¼ê³  í•´ì„œ ë„ë•ì ìœ¼ë¡œ í›Œë¥­í•˜ë‹¤ëŠ” ëœ»ì´ ì•„ë‹ˆë¼ ë„ë•ê³¼ ë¬´ê´€í•˜ë‹¤ëŠ” ë§ê³¼ ëŒ€ë¹„ë˜ëŠ” ëœ»ìœ¼ë¡œ ì“°ê³  ìˆë‹¤.<conj>ê·¸ëŸ°ë°</conj> ì–´ë¦° ì•„ì´ëŠ” ì¸ê²©ì²´ë¡œì„œì˜ ìµœì†Œí•œì˜ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ê³  ìˆëŠ”ì§€ê°€ ë…¼ë€ì´ ë  ìˆ˜ ìˆë‹¤. ì´ì— ëŒ€í•´ ë¡¤ìŠ¤ëŠ” ë„ë•ì  ì¸ê²©ì„ ê·œì •í•˜ëŠ” ìµœì†Œí•œì˜ ìš”êµ¬ ì¡°ê±´ì€ ì ì¬ì  ëŠ¥ë ¥ì´ì§€ ê·¸ê²ƒì˜ ì‹¤í˜„ ì—¬ë¶€ê°€ ì•„ë‹ˆê¸°ì— ì–´ë¦° ì•„ì´ë„ í‰ë“±í•œ ì¡´ì¬ë¼ê³  ë§í•œë‹¤. ì„±ì–´ëŠ” ìœ„ì™€ ê°™ì€ ë¡¤ìŠ¤ì˜ ì‹œë„ë¥¼ ë¹„íŒí•œë‹¤. ë„ë•ì— ëŒ€í•œ ë¯¼ê°ì„±ì˜ ìˆ˜ì¤€ì€ ì‚¬ëŒì— ë”°ë¼ ë‹¤ë¥´ë‹¤. ê·¸ë˜ì„œ ë„ë•ì  ì¸ê²©ì˜ ëŠ¥ë ¥ì´ ê·¸ë ‡ê²Œ ì¤‘ìš”í•˜ë‹¤ë©´ ê·¸ê²ƒì„ ê°–ì¶˜ ì •ë„ì— ë”°ë¼ ë„ë•ì  ìœ„ê³„ë¥¼ ë‹¤ë¥´ê²Œ í•˜ì§€ ë§ì•„ì•¼ í•  ì´ìœ ê°€ ë¶„ëª…í•˜ì§€ ì•Šë‹¤ê³  ë§í•œë‹¤. ê·¸ë¦¬ê³  í‰ë“±í•œ ê¶Œë¦¬ë¥¼ ê°–ëŠ” ì¡´ì¬ê°€ ë˜ê¸° ìœ„í•œ ìµœì†Œí•œì˜ ê²½ê³„ì„ ì„ ì–´ë””ì— ê·¸ì–´ì•¼ í•˜ëŠ”ì§€ë„ ë¬¸ì œë¡œ ë‚¨ëŠ”ë‹¤ê³  ë³¸ë‹¤. í•œí¸ ë¡¤ìŠ¤ì—ì„œëŠ” ë„ë•ì ì¸ ëŠ¥ë ¥ì„ íƒœì–´ë‚  ë•Œë¶€í„° ê°€ì§€ê³  ìˆì§€ ì•Šê±°ë‚˜ ì˜êµ¬ì ìœ¼ë¡œ ìƒì‹¤í•œ ì‚¬ëŒì€ ë„ë”ì € ì§€ìœ„ë¥¼ ê°€ì§€ê³  ìˆì§€ ëª»í•˜ê²Œ ë˜ëŠ”ë°, ì´ëŠ” ëª½ìƒì ì¸ í‰ë“± ê°œë…ê³¼ ì–´ê¸‹ë‚œë‹¤. ê·¸ë˜ì„œ ì‹±ì–´ëŠ” í‰ë“±ì˜ ê·¼ê±°ë¡œ â€˜ì´ìµ í‰ë“± ê³ ë ¤ì˜ ì›ì¹™ ì„ ë‚´ì„¸ìš´ë‹¤. ê·¸ì— ë”°ë¥´ë©´ ì–´ë–¤ ì¡´ì¬ê°€ ì´ìµ,<conj>ì¦‰</conj> ì´í•´ê´€ê³„ë¥¼ ê°–ê¸° ìœ„í•´ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê³ í†µê³¼ ì¾Œë½ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°–ê³  ìˆì–´ì•¼ í•œë‹¤. ê·¸ë¦¬ê³  ê·¸ ëŠ¥ë ¥ì„ ê°€ì§„ ì¡´ì¬ëŠ” ì´í•´ê´€ê³„ë¥¼ ê°€ì§„ ì¡´ì¬ì´ê¸°<conj>ë•Œë¬¸ì—</conj> í‰ë“±í•œ ë„ë”ì € ê³ ë ¤ì˜ ëŒ€ìƒì´ ëœë‹¤. ì´ë•Œ ì´í•´ ê´€ê³„ê°€ ê°•í•œ ì¡´ì¬ë¥¼ ë” ëŒ€ìš°í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë‹¤. ë°˜ë©´ì— ê·¸ ëŠ¥ë ¥ì„ ê°–ì§€ ëª»í•œ ì¡´ì¬ëŠ” ì•„ë¬´ëŸ° ì„ í˜¸ëƒ ì´ìµë„ ê°–ì§€ ì•Šê¸° ë•Œë¬¸ì— í‰ë“±í•œ ë„ë•ì  ê³ ë ¤ì˜ ëŒ€ìƒì´ ë˜ì§€ ì•ŠëŠ”ë‹¤.<conj> </conj>í‰ë“±ì€ ììœ ì™€ ë”ë¶ˆì–´ ê·¼ëŒ€ ì‚¬íšŒì˜ í•µì‹¬ ì´ë…ìœ¼ë¡œ ìë¦¬ ì¡ê³  ìˆë‹¤. ì¸ê°„ì€ ê°€ë ¹ ì¸ì¢…ì´ë‚˜ ì„±ë³„ê³¼ ìƒê´€ì—†ì´ ëˆ„êµ¬ë‚˜ í‰ë“±í•˜ë‹¤ê³  ìƒê°í•œë‹¤. ëª¨ë“  ì¸ê°„ì€ í‰ë“±í•˜ë‹¤ê³  ë§í•˜ëŠ”ë°, ì´ ë§ì€ ë¬´ìŠ¨ ëœ»ì¼ê¹Œ?<conj>ê·¸ë¦¬ê³ </conj> ê·¸ ê·¼ê±°ëŠ” ë¬´ì—‡ì¸ê°€? ì¼ë‹¨ ì´ ë§ì„ ëª¨ë“  ì¸ê°„ì„ ëª¨ë“  ì¸¡ë©´ì—ì„œ ë˜‘ê°™ì´ ëŒ€ìš°í•˜ëŠ” ì ˆëŒ€ì¹™ í‰ë“±ìœ¼ë¡œ ìƒê°í•˜ëŠ” ì´ëŠ” ì—†ë‹¤. ì¸ê°„ì€ ì €ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ê°€ì§€ê³  ëŒ€ì–´ë‚œ ëŠ¥ë ¥ê³¼ ì†Œì§ˆì„ ë˜‘ê°™ê²Œ ë§Œë“¤ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì´ë‹¤. ì ˆëŒ€ì  í‰ë“±ì€ ê°œì¸ì˜ ê°œì„±ì´ëƒ ììœ¨ì„± ë“±ì˜ ê°€ì¹˜ì™€ ì¶©ëŒí•˜ê¸°ë„ í•œë‹¤. í‰ë“±ì— ëŒ€í•œ ìš”êµ¬ëŠ” ëª¨ë“  ë¶ˆí‰ë“±ì„ ì•…ìœ¼ë¡œ ë³´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì¶©ë¶„í•œ ì´ìœ ê°€ ì œì‹œë˜ì§€ ì•Šì€ ë¶ˆí‰ë“±ì„ ì œê±°í•˜ëŠ” ë° ëª©í‘œë¥¼ ë‘ê³  ìˆë‹¤. â€˜ì´ìœ  ì—†ëŠ” ì°¨ë³„ ê¸ˆì§€â€™ë¼ëŠ” ì¡°ê±´ì  í‰ë“± ì›ì¹™ì€ ì°¨ë³„ ëŒ€ìš°ë¥¼ í•  ë•ŒëŠ” ì´ìœ ë¥¼ ì œì‹œí•  ê²ƒì„ ìš”êµ¬í•˜ê³  ìˆë‹¤. ì´ê²ƒì€ ì–´ë–¤ ì´ìœ ê°€ ì œì‹œëœë‹¤ë©´ íŠ¹ì •í•œ ë¶€ë¥˜ì— ì†í•˜ëŠ” ì‚¬ëŒë“¤ì—ê²ŒëŠ” í‰ë“±í•œ ëŒ€ìš°ë¥¼, ê·¸ ë¶€ë¥˜ì— ì†í•˜ì§€ ì•ŠëŠ” ì‚¬ëŒë“¤ì—ê²ŒëŠ” ì°¨ë³„ì € ëŒ€ìš°ë¥¼ í•˜ëŠ” ê²ƒì„ í—ˆìš©í•œë‹¤. ê·¸ë ‡ë‹¤ë©´ ì‚¬ëŒë“¤ì„ íŠ¹ì •í•œ ë¶€ë¥˜ë¡œ êµ¬ë¶„í•˜ëŠ” ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€? ì´ê²ƒì€ ë°”ë¡œ í‰ë“±ì˜ ê·¼ê±°ì— ëŒ€í•œ ë¬¼ìŒì´ë‹¤. ê·¼ëŒ€ì˜ ì—¬ëŸ¬ ì¸ê¶Œ ì„ ì–¸ì— ë‚˜íƒ€ë‚œ í‰ë“± ê°œë…ì€ ê°œì¸ë“¤ ì‚¬ì´ì˜ í‰ë“±ì„±ì„ íƒ€ê³ ë‚œ ìì—°ì  ê¶Œë¦¬ë¡œ ê°„ì£¼í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ ì´ëŸ¬í•œ ìì—°ê¶Œ ì´ë¡ ì€ ë¬´ì—‡ì´ ìì—°ì  ê¶Œë¦¬ì´ê³  ê¶Œë¦¬ì˜ ì¡´ì¬ê°€ ìëª…í•œ ì´ìœ ê°€ ë¬´ì—‡ì¸ì§€ ë“±ì˜ ë¬¸ì œì— ë¶€ë”ªíˆê²Œ ëœë‹¤.<conj>ê·¸ë˜ì„œ</conj> ë¡¤ìŠ¤ëŠ” ê¸°ì¡´ì˜ ìì—°ê¶Œ ì‚¬ìƒì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ” ë°©ì‹œìœ¼ë¡œ ì¸ê°„ í‰ë“±ì˜ ê·¼ê±°ë¥¼ ë§ˆëŸ° í•˜ë ¤ê³  í•œë‹¤. ê·¸ëŠ” ì–´ë–¤ ê·œì¹™ì´ ê³µí‰í•˜ê³  ì¼ê´€ë˜ê²Œ ìš´ì˜ë˜ë©°, ê·¸ ê·œì¹™ì— ë”°ë¼ ìœ ì‚¬í•œ ê²½ìš°ëŠ” ìœ ì‚¬í•˜ê²Œ ì·¨ê¸‰ëœë‹¤ë©´ í˜•ì‹ì  ì •ì˜ëŠ” ì‹¤í˜„ëœë‹¤ê³  ë³¸ë‹¤. í•˜ì§€ë§Œ ë¡¤ìŠ¤ëŠ” í˜•ì‹ì € ì •ì˜ì— ë”°ë¼ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì •ì˜ë¥¼ ë‹´ë³´í•  ìˆ˜ ì—†ë‹¤ê³  ìƒê°í•œë‹¤. ê·¸ ê·œì¹™ì´ ë” ë†’ì€ ë„ë•ì  ê¶Œìœ„ë¥¼ ì§€ë‹Œ ë‹¤ë¥¸ ì´ë„˜ê³¼ ì¶©ëŒí•  ìˆ˜ ì—ˆê¸°ì—, ì‹¤ì§ˆì  ì •ì˜ê°€ ë³´ì¥ë˜ê¸° ìœ„í•´ì„œëŠ” ê·œì¹™ì˜ ë‚´ìš©ì´ ì¤‘ìš”í•œ ê²ƒì´ë‹¤. ë¡¤ìŠ¤ëŠ” ì¸ê°„ í‰ë“±ì˜ ê·¼ê±°ë¥¼ ì„¤ëª…í•˜ë©´ì„œ ì˜ì—­ ì„±ì§ˆ (range property) ê°œë…ì„ ë„ì…í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì–´ë–¤ ì›ì˜ ë‚´ë¶€ì— ìˆëŠ” ì ë“¤ì€ ê·¸ ìœ„ ì¹˜ê°€ ì„œë¡œ ë‹¤ë¥´ì§€ë§Œ ì›ì˜ ë‚´ë¶€ì— ìˆë‹¤ëŠ” ì ì—ì„œ ë™ì¼í•œ ì˜ì—­ ì„±ì§ˆ ì„ ê°–ëŠ”ë‹¤. ë°˜ë©´ì— ì›ì˜ ë‚´ë¶€ì— ìˆëŠ” ì§‘ê³¼ ì›ì˜ ì™¸ë¶€ì— ì˜€ëŠ” ì ì€ ì›ì˜ ê²½ê³„ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ ì„œë¡œ ë‹¤ë¥¸ ì˜ì—­ ì„±ì§ˆì„ ê°–ëŠ”ë‹¤. ê·¸ëŠ” í‰ë“± í•œ ëŒ€ìš°ë¥¼ ë°›ê¸° ìœ„í•œ ì˜ì—­ ì„±ì§ˆë¡œì„œ â€˜ë„ë•ì  ì¸ê²© ì„ ì œì‹œí•œë‹¤. ë„ë•ì  ì¸ê²©ì´ë€ ë„ë•ì  í˜¸ì†Œê°€ ê°€ëŠ¥í•˜ê³  ê·¸ëŸ° í˜¸ì†Œì— ê´€ì‹¬ì„ ê¸°ìš¸ ì´ëŠ” ëŠ¥ë ¥ì´ ìˆë‹¤ëŠ” ê²ƒì¸ë°, ì´ ëŠ¥ë ¥ì„ ìµœì†Œì¹˜ë§Œ ê°–ê³  ìˆë‹¤ë©´ í‰ë“±í•œ ëŒ€ìš°ì— ëŒ€í•œ ê¶Œí•œì„ ê°–ê²Œ ëœë‹¤. ë„ë•ì  ì¸ê²©ì´ë¼ê³  í•´ì„œ ë„ë•ì ìœ¼ë¡œ í›Œë¥­í•˜ë‹¤ëŠ” ëœ»ì´ ì•„ë‹ˆë¼ ë„ë•ê³¼ ë¬´ê´€í•˜ë‹¤ëŠ” ë§ê³¼ ëŒ€ë¹„ë˜ëŠ” ëœ»ìœ¼ë¡œ ì“°ê³  ìˆë‹¤.<conj>ê·¸ëŸ°ë°</conj> ì–´ë¦° ì•„ì´ëŠ” ì¸ê²©ì²´ë¡œì„œì˜ ìµœì†Œí•œì˜ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ê³  ìˆëŠ”ì§€ê°€ ë…¼ë€ì´ ë  ìˆ˜ ìˆë‹¤. ì´ì— ëŒ€í•´ ë¡¤ìŠ¤ëŠ” ë„ë•ì  ì¸ê²©ì„ ê·œì •í•˜ëŠ” ìµœì†Œí•œì˜ ìš”êµ¬ ì¡°ê±´ì€ ì ì¬ì  ëŠ¥ë ¥ì´ì§€ ê·¸ê²ƒì˜ ì‹¤í˜„ ì—¬ë¶€ê°€ ì•„ë‹ˆê¸°ì— ì–´ë¦° ì•„ì´ë„ í‰ë“±í•œ ì¡´ì¬ë¼ê³  ë§í•œë‹¤. ì„±ì–´ëŠ” ìœ„ì™€ ê°™ì€ ë¡¤ìŠ¤ì˜ ì‹œë„ë¥¼ ë¹„íŒí•œë‹¤. ë„ë•ì— ëŒ€í•œ ë¯¼ê°ì„±ì˜ ìˆ˜ì¤€ì€ ì‚¬ëŒì— ë”°ë¼ ë‹¤ë¥´ë‹¤. ê·¸ë˜ì„œ ë„ë•ì  ì¸ê²©ì˜ ëŠ¥ë ¥ì´ ê·¸ë ‡ê²Œ ì¤‘ìš”í•˜ë‹¤ë©´ ê·¸ê²ƒì„ ê°–ì¶˜ ì •ë„ì— ë”°ë¼ ë„ë•ì  ìœ„ê³„ë¥¼ ë‹¤ë¥´ê²Œ í•˜ì§€ ë§ì•„ì•¼ í•  ì´ìœ ê°€ ë¶„ëª…í•˜ì§€ ì•Šë‹¤ê³  ë§í•œë‹¤. ê·¸ë¦¬ê³  í‰ë“±í•œ ê¶Œë¦¬ë¥¼ ê°–ëŠ” ì¡´ì¬ê°€ ë˜ê¸° ìœ„í•œ ìµœì†Œí•œì˜ ê²½ê³„ì„ ì„ ì–´ë””ì— ê·¸ì–´ì•¼ í•˜ëŠ”ì§€ë„ ë¬¸ì œë¡œ ë‚¨ëŠ”ë‹¤ê³  ë³¸ë‹¤. í•œí¸ ë¡¤ìŠ¤ì—ì„œëŠ” ë„ë•ì ì¸ ëŠ¥ë ¥ì„ íƒœì–´ë‚  ë•Œë¶€í„° ê°€ì§€ê³  ìˆì§€ ì•Šê±°ë‚˜ ì˜êµ¬ì ìœ¼ë¡œ ìƒì‹¤í•œ ì‚¬ëŒì€ ë„ë”ì € ì§€ìœ„ë¥¼ ê°€ì§€ê³  ìˆì§€ ëª»í•˜ê²Œ ë˜ëŠ”ë°, ì´ëŠ” ëª½ìƒì ì¸ í‰ë“± ê°œë…ê³¼ ì–´ê¸‹ë‚œë‹¤. ê·¸ë˜ì„œ ì‹±ì–´ëŠ” í‰ë“±ì˜ ê·¼ê±°ë¡œ â€˜ì´ìµ í‰ë“± ê³ ë ¤ì˜ ì›ì¹™ ì„ ë‚´ì„¸ìš´ë‹¤. ê·¸ì— ë”°ë¥´ë©´ ì–´ë–¤ ì¡´ì¬ê°€ ì´ìµ,<conj>ì¦‰</conj> ì´í•´ê´€ê³„ë¥¼ ê°–ê¸° ìœ„í•´ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê³ í†µê³¼ ì¾Œë½ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°–ê³  ìˆì–´ì•¼ í•œë‹¤. ê·¸ë¦¬ê³  ê·¸ ëŠ¥ë ¥ì„ ê°€ì§„ ì¡´ì¬ëŠ” ì´í•´ê´€ê³„ë¥¼ ê°€ì§„ ì¡´ì¬ì´ê¸°<conj>ë•Œë¬¸ì—</conj> í‰ë“±í•œ ë„ë”ì € ê³ ë ¤ì˜ ëŒ€ìƒì´ ëœë‹¤. ì´ë•Œ ì´í•´ ê´€ê³„ê°€ ê°•í•œ ì¡´ì¬ë¥¼ ë” ëŒ€ìš°í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë‹¤. ë°˜ë©´ì— ê·¸ ëŠ¥ë ¥ì„ ê°–ì§€ ëª»í•œ ì¡´ì¬ëŠ” ì•„ë¬´ëŸ° ì„ í˜¸ëƒ ì´ìµë„ ê°–ì§€ ì•Šê¸° ë•Œë¬¸ì— í‰ë“±í•œ ë„ë•ì  ê³ ë ¤ì˜ ëŒ€ìƒì´ ë˜ì§€ ì•ŠëŠ”ë‹¤. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuavVrBUb1p-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "84ff01ef-dae3-499d-8e05-6ec51872c32e"
      },
      "source": [
        "ls = []\n",
        "ls.append(h.pos(text))\n",
        "m = []\n",
        "for i in ls:\n",
        "  for word, pos in i:\n",
        "    if pos==\"M\":\n",
        "      m.append(word)\n",
        "\n",
        "print(m)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ê°€ë ¹', 'ìƒê´€ì—†ì´', 'ëª¨ë“ ', 'ì´', 'ë¬´ìŠ¨', 'ê·¸ë¦¬ê³ ', 'ê·¸', 'ì´', 'ëª¨ë“ ', 'ëª¨ë“ ', 'ë˜‘ê°™ì´', 'ëª¨ë“ ', 'ì–´ë–¤', 'ê·¸', 'ê·¸ë ‡ë‹¤ë©´', 'ë°”ë¡œ', 'ì—¬ëŸ¬', 'ê·¸ë˜ì„œ', 'ì–´ë–¤', 'ê·¸', 'ê·¸', 'ë”', 'ë‹¤ë¥¸', 'ì–´ë–¤', 'ê·¸', 'ì„œë¡œ', 'ì„œë¡œ', 'ë‹¤ë¥¸', 'ì´', 'ê·¸ëŸ°ë°', 'ê·¸ë˜ì„œ', 'ê·¸ë¦¬ê³ ', 'ê·¸ë˜ì„œ', 'ì–´ë–¤', 'ì¦‰', 'ê·¸ë¦¬ê³ ', 'ê·¸', 'ë”', 'ê·¸', 'ì•„ë¬´ëŸ°']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JS0FMkeN8Sb",
        "colab_type": "text"
      },
      "source": [
        "## Relation Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Af1flDKI9M8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3de3afba-e435-4954-f1b0-a3a30615ceb5"
      },
      "source": [
        "parser = frame_parser.FrameParser(model_path=path, language='ko')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "srl model: framenet\n",
            "language: ko\n",
            "version: 1.2\n",
            "using viterbi: False\n",
            "using masking: True\n",
            "pretrained BERT: bert-base-multilingual-cased\n",
            "using TGT special token: True\n",
            "used dictionary:\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lu2idx.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lufrmap.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
            "...loaded model path: /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "...model is loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuHEQofWAsnA",
        "colab_type": "text"
      },
      "source": [
        "### Linked List Implemented to Show the whole list of sentences and their parsed tags in a consecutive manner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wIph64I5OnLZ",
        "colab": {}
      },
      "source": [
        "def split_into_sentences(object):\n",
        "  ls = kss.split_sentences(object)\n",
        "  return ls\n",
        "\n",
        "def frameParse(text):\n",
        "  parser = frame_parser.FrameParser(model_path=path, language='ko')\n",
        "  parsed = parser.parser(text, sent_id='1', result_format='conll')\n",
        "  return parsed\n",
        "  \n",
        "\n",
        "def sortCandidate(parsed, num_candidates):\n",
        "  for i in range(len(parsed)):\n",
        "    count=0\n",
        "    for element in parsed[i][3]:\n",
        "      if element.startswith(\"O\"):\n",
        "        count+=1\n",
        "  q[i] = len(words) - count\n",
        "  hq = heapq.nlargest(num_candidates, q)\n",
        "  indices.append(q.index(hq[idx]))\n",
        "  # for idx in range(num_candidates):\n",
        "  #   temp = parsed[q.index(hq[idx])]\n",
        "  #   words = temp[0]\n",
        "  #   [[row[i] for row in temp] for i in range(len(words))]\n",
        "  return indices\n",
        "\n",
        "\n",
        "def findConsecutiveBIO(words, tag):\n",
        "  began = False\n",
        "  count = 0\n",
        "  q = deque(words)\n",
        "  for i in range(len(words)):\n",
        "    if tag[i]=='O':\n",
        "      q.popleft()\n",
        "    if tag[i].startswith('B'):\n",
        "      began=True\n",
        "    if began & tag[i].startswith('I'):\n",
        "      count+=1\n",
        "  return q\n",
        "\n",
        "# Linked List êµ¬í˜„í•´ì„œ parsed í›„ë³´êµ°ì— ì‚¬ìš©\n",
        "class Node:\n",
        "    def __init__(self, data):\n",
        "        self.words = data[0]\n",
        "        self.tags = data[3]\n",
        "        self.next = None\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str((self.words, self.tags))\n",
        "\n",
        "class LinkedList:\n",
        "  def __init__(self):\n",
        "      self.head = None\n",
        "\n",
        "  def __repr__(self):\n",
        "      node = self.head\n",
        "      nodes = []\n",
        "      while node is not None:\n",
        "          nodes.append(str(node.tags))\n",
        "          node = node.next\n",
        "      nodes.append(\"None\")\n",
        "      return ' -> '.join(nodes)\n",
        "  \n",
        "class LinkedList:\n",
        "  def __init__(self):\n",
        "      self.head = None\n",
        "\n",
        "  def __repr__(self):\n",
        "      node = self.head\n",
        "      nodes = []\n",
        "      while node is not None:\n",
        "          nodes.append(str(node.tags))\n",
        "          node = node.next\n",
        "      nodes.append(\"None\")\n",
        "      return ' -> '.join(nodes)\n",
        "\n",
        "def extractFrame(text):\n",
        "  ls = split_into_sentences(text)\n",
        "  final = {}\n",
        "  \n",
        "  for idx in range(len(ls)):\n",
        "    parsed = frameParse(ls[idx]) # candidates ìƒì„±\n",
        "    final.setdefault(idx,str)\n",
        "    parsedList =  LinkedList()\n",
        "    for j in range(len(parsed)):\n",
        "      parsed_candidate = parsed[j]\n",
        "      new_node = Node(parsed_candidate)\n",
        "      if j == 0:\n",
        "        old_node = new_node\n",
        "        parsedList.head = old_node\n",
        "      elif j==len(parsed)-1:\n",
        "        old_node.next = new_node\n",
        "        new_node.next = None\n",
        "        print(idx,'  ',parsedList)\n",
        "        final[idx] = parsedList\n",
        "      else:\n",
        "        old_node.next = new_node\n",
        "        old_node = new_node\n",
        "  return final\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD2QZjRqZaM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(text):\n",
        "  all = extractFrame(text)\n",
        "  s = \"\"\n",
        "  res = {}\n",
        "\n",
        "  i = 1\n",
        "  res.setdefault(i,tuple)\n",
        "  for k, v in all.items():\n",
        "    a = v.head\n",
        "    while a is not None:\n",
        "      temp = \" \"\n",
        "      if len(a.words) == len(a.tags):\n",
        "        q = findConsecutiveBIO(a.words, a.tags)\n",
        "      else:\n",
        "        print(\"ERROR OCCURED\")\n",
        "        \n",
        "      count = len(a.words)\n",
        "      for tag in a.tags:\n",
        "       if tag.startswith(\"O\"):\n",
        "          count -= 1\n",
        "      if count > len(a.words)*0.5:\n",
        "        print(\"The threshold is reached !! ğŸ˜› ğŸ˜ ğŸ˜œ ğŸ¤ª ğŸ¤¨ ğŸ§ ğŸ¤“ ğŸ˜ ğŸ¤© ğŸ¥³ ğŸ˜\")\n",
        "        temp = \" \".join(q) \n",
        "        print(temp)\n",
        "        words = a.words\n",
        "        tags = a.tags\n",
        "      res[i] = (a.words, a.tags , \" \".join(q))\n",
        "      a = a.next\n",
        "    i+=1\n",
        "  return res\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIIiD0vrpdmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94d6d5dd-1a4c-43b5-d646-960fb1ef00f3"
      },
      "source": [
        "extracted = main(text)\n",
        "pprint(extracted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "srl model: framenet\n",
            "language: ko\n",
            "version: 1.2\n",
            "using viterbi: False\n",
            "using masking: True\n",
            "pretrained BERT: bert-base-multilingual-cased\n",
            "using TGT special token: True\n",
            "used dictionary:\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lu2idx.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lufrmap.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
            "...loaded model path: /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "...model is loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred_logits = sm(masked_logit).view(1,-1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'I-Class', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Time', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'I-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'O', 'O', 'I-Trajector_event', 'I-Trajector_event', 'O', 'I-Trajector_event'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'I-Time', 'I-Time', 'I-Time', 'I-Time', 'I-Time', 'I-Time', 'I-Time', 'I-Time', 'B-Old', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'I-Means', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Time', 'O', 'I-Goal', 'I-Goal', 'O', 'O', 'O'] -> None\n",
            "srl model: framenet\n",
            "language: ko\n",
            "version: 1.2\n",
            "using viterbi: False\n",
            "using masking: True\n",
            "pretrained BERT: bert-base-multilingual-cased\n",
            "using TGT special token: True\n",
            "used dictionary:\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lu2idx.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lufrmap.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
            "...loaded model path: /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "...model is loaded\n",
            "1    ['B-Time', 'B-Theme', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Time', 'B-Goal', 'I-Goal', 'O', 'B-Items', 'O', 'O', 'O', 'O'] -> None\n",
            "srl model: framenet\n",
            "language: ko\n",
            "version: 1.2\n",
            "using viterbi: False\n",
            "using masking: True\n",
            "pretrained BERT: bert-base-multilingual-cased\n",
            "using TGT special token: True\n",
            "used dictionary:\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lu2idx.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lufrmap.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
            "...loaded model path: /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "...model is loaded\n",
            "2    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Agent', 'I-Instrument', 'I-Instrument', 'I-Instrument', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Entity', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['B-Entity', 'I-Entity', 'I-Entity', 'I-Entity', 'I-Entity', 'I-Entity', 'I-Entity', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] -> None\n",
            "The threshold is reached !! ğŸ˜› ğŸ˜ ğŸ˜œ ğŸ¤ª ğŸ¤¨ ğŸ§ ğŸ¤“ ğŸ˜ ğŸ¤© ğŸ¥³ ğŸ˜\n",
            "ì´ìƒ ì œ ê¸°ëŠ¥ì„ í•˜ì§€ëª»í•  ë•Œì— ì´ë¥¼ ëŒ€ì²´í•˜ê¸° ìœ„í•´ ì´ì‹ì„ ì‹¤ì‹œí•œë‹¤.\n",
            "The threshold is reached !! ğŸ˜› ğŸ˜ ğŸ˜œ ğŸ¤ª ğŸ¤¨ ğŸ§ ğŸ¤“ ğŸ˜ ğŸ¤© ğŸ¥³ ğŸ˜\n",
            "ì œ ê¸°ëŠ¥ì„ í•˜ì§€ëª»í•  ë•Œì— ì´ë¥¼ ëŒ€ì²´í•˜ê¸° ìœ„í•´ ì´ì‹ì„ ì‹¤ì‹œí•œë‹¤.\n",
            "ERROR OCCURED\n",
            "{1: (['ì‹ ì²´ì˜',\n",
            "      'ì„¸í¬,',\n",
            "      'ì¡°ì§,',\n",
            "      'ì¥ê¸°ê°€',\n",
            "      'ì†ìƒë˜ì–´',\n",
            "      'ë”',\n",
            "      'ì´ìƒ',\n",
            "      'ì œ',\n",
            "      'ê¸°ëŠ¥ì„',\n",
            "      'í•˜ì§€ëª»í• ',\n",
            "      'ë•Œì—',\n",
            "      'ì´ë¥¼',\n",
            "      'ëŒ€ì²´í•˜ê¸°',\n",
            "      'ìœ„í•´',\n",
            "      'ì´ì‹ì„',\n",
            "      'ì‹¤ì‹œí•œë‹¤.'],\n",
            "     ['O',\n",
            "      'O',\n",
            "      'I-Means',\n",
            "      'O',\n",
            "      'O',\n",
            "      'O',\n",
            "      'O',\n",
            "      'O',\n",
            "      'O',\n",
            "      'I-Time',\n",
            "      'O',\n",
            "      'I-Goal',\n",
            "      'I-Goal',\n",
            "      'O',\n",
            "      'O',\n",
            "      'O'],\n",
            "     'ëŒ€ì²´í•˜ê¸° ìœ„í•´ ì´ì‹ì„ ì‹¤ì‹œí•œë‹¤.'),\n",
            " 2: (['ì´ë•Œ', 'ì´ì‹ìœ¼ë¡œ', 'ì˜®ê²¨', 'ë¶™ì´ëŠ”', 'ì„¸í¬,', 'ì¡°ì§,', 'ì¥ê¸°ë¥¼', 'ì´ì‹í¸ì´ë¼', 'í•œë‹¤.'],\n",
            "     ['B-Time', 'B-Goal', 'I-Goal', 'O', 'B-Items', 'O', 'O', 'O', 'O'],\n",
            "     'ì¡°ì§, ì¥ê¸°ë¥¼ ì´ì‹í¸ì´ë¼ í•œë‹¤.'),\n",
            " 3: (['ìì‹ ì´ë‚˜',\n",
            "      'ì¼ë€ì„±',\n",
            "      'ìŒë‘¥ì´ì˜',\n",
            "      'ì´ì‹í¸ì„',\n",
            "      'ì´ìš©í• ',\n",
            "      '',\n",
            "      'ìˆ˜',\n",
            "      'ì—†ë‹¤ë©´',\n",
            "      'ë‹¤ë¥¸',\n",
            "      'ì‚¬ëŒì˜',\n",
            "      'ì´ì‹í¸ìœ¼ë¡œ',\n",
            "      'â€˜ë™ì¢…',\n",
            "      'ì´ì‹â€™ì„',\n",
            "      'ì‹¤ì‹œí•œë‹¤.'],\n",
            "     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
            "     '')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvm4aMtEz1A1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "6f28df78-5b42-4d60-a3e2-d78b92ad9c89"
      },
      "source": [
        "pprint(extracted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: (['ì‹ ì²´ì˜',\n",
            "      'ì„¸í¬,',\n",
            "      'ì¡°ì§,',\n",
            "      'ì¥ê¸°ê°€',\n",
            "      'ì†ìƒë˜ì–´',\n",
            "      'ë”',\n",
            "      'ì´ìƒ',\n",
            "      'ì œ',\n",
            "      'ê¸°ëŠ¥ì„',\n",
            "      'í•˜ì§€ëª»í• ',\n",
            "      'ë•Œì—',\n",
            "      'ì´ë¥¼',\n",
            "      'ëŒ€ì²´í•˜ê¸°',\n",
            "      'ìœ„í•´',\n",
            "      'ì´ì‹ì„',\n",
            "      'ì‹¤ì‹œí•œë‹¤.'],\n",
            "     ['O',\n",
            "      'O',\n",
            "      'I-Means',\n",
            "      'O',\n",
            "      'O',\n",
            "      'O',\n",
            "      'O',\n",
            "      'O',\n",
            "      'O',\n",
            "      'I-Time',\n",
            "      'O',\n",
            "      'I-Goal',\n",
            "      'I-Goal',\n",
            "      'O',\n",
            "      'O',\n",
            "      'O'],\n",
            "     ' '),\n",
            " 2: (['ì´ë•Œ', 'ì´ì‹ìœ¼ë¡œ', 'ì˜®ê²¨', 'ë¶™ì´ëŠ”', 'ì„¸í¬,', 'ì¡°ì§,', 'ì¥ê¸°ë¥¼', 'ì´ì‹í¸ì´ë¼', 'í•œë‹¤.'],\n",
            "     ['B-Time', 'B-Goal', 'I-Goal', 'O', 'B-Items', 'O', 'O', 'O', 'O'],\n",
            "     ' '),\n",
            " 3: (['ìì‹ ì´ë‚˜',\n",
            "      'ì¼ë€ì„±',\n",
            "      'ìŒë‘¥ì´ì˜',\n",
            "      'ì´ì‹í¸ì„',\n",
            "      'ì´ìš©í• ',\n",
            "      '',\n",
            "      'ìˆ˜',\n",
            "      'ì—†ë‹¤ë©´',\n",
            "      'ë‹¤ë¥¸',\n",
            "      'ì‚¬ëŒì˜',\n",
            "      'ì´ì‹í¸ìœ¼ë¡œ',\n",
            "      'â€˜ë™ì¢…',\n",
            "      'ì´ì‹â€™ì„',\n",
            "      'ì‹¤ì‹œí•œë‹¤.'],\n",
            "     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
            "     ' ')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQNkF3aGty_0",
        "colab_type": "text"
      },
      "source": [
        "### TODO : ì—¬ê¸°ì„œë¶€í„° extractedë¥¼ ê°€ì§€ê³  purpose / goal / effect / entity ë“±ì„ ì°¾ì•„ì•¼í•¨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf62cktfw2C1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for k, tup in extracted.items():\n",
        "  a, b, c = tup\n",
        "  roles = [0]*len(b)\n",
        "  words = [0]*len(b)\n",
        "  for i in range(len(b)):\n",
        "    try: \n",
        "      roles[i] = b[i].split(\"-\")[1] \n",
        "      \n",
        "    except: \n",
        "      roles[i] = b[i].split(\"-\")[0]\n",
        "  print(roles)\n",
        "  for _ in roles:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S7zGTQO4BUO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "326d4f22-e8b0-4f94-f2dd-23251248d598"
      },
      "source": [
        "# 1st sentence : GOALS & MEANS \n",
        "\n",
        "parsed = parser.parser(ls[0], sent_id='1', result_format='conll')\n",
        "words = parsed[0][0]\n",
        "print(\"ğŸ˜€ Words vector from sentence \",words)\n",
        "q = [-1]*len(parsed)\n",
        "for i in range(len(parsed)):\n",
        "  count=0\n",
        "  for element in parsed[i][3]:\n",
        "    if element.startswith(\"O\"):\n",
        "      count+=1\n",
        "  q[i] = len(words) - count\n",
        "hq = heapq.nlargest(2, q)\n",
        "\n",
        "\n",
        "print(\"Number of parsed candidates \",len(parsed))\n",
        "print(q, heapq.nlargest(2, q)) # ì²«ë²ˆì§¸ ê²½ìš° ì‚¬ìš©\n",
        "\n",
        "\n",
        "words = parsed[0][0]\n",
        "roles = parsed[0][2]\n",
        "tagged = parsed[0][3]\n",
        "for idx in range(len(tagged)):\n",
        "  try:\n",
        "    roles[i] = tagged[i].split(\"-\")[1]\n",
        "  except:\n",
        "    roles[i] = tagged[i].split(\"-\")[0]\n",
        "\n",
        "print(\"roles \",roles)\n",
        "\n",
        "goals = []\n",
        "means = []\n",
        "for _ in range(len(words)):\n",
        "  if roles[_]==\"Goal\":\n",
        "    goals.append(words[_])\n",
        "  if roles[_]=='Means':\n",
        "    means.append(words[_])\n",
        "\n",
        "# MEANS\n",
        "MEANS = ' '.join(means)\n",
        "pos = h.pos(MEANS)\n",
        "imp = []\n",
        "for tup in h.pos(MEANS):\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "MEANS_TRUNCATED = ' '.join(imp)\n",
        "print(MEANS_TRUNCATED)\n",
        "\n",
        "# GOALS\n",
        "GOAL = ' '.join(goals)\n",
        "pos = h.pos(GOAL)\n",
        "imp = []\n",
        "for tup in h.pos(GOAL):\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "GOAL_TRUNCATED = ' '.join(imp)\n",
        "print(GOAL_TRUNCATED)\n",
        "\n",
        "final_string = MEANS_TRUNCATED + ' -- >' + GOAL_TRUNCATED\n",
        "print(\"ğŸ˜€ final string to be inserted\",final_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['TEXT2PPTXì˜', 'êµ¬í˜„í•˜ê¸°', 'ìœ„í•´', 'two', 'track', 'processë¥¼', 'ê±°ì³¤ìŠµë‹ˆë‹¤.'], ['_', '_', 'ìœ„í•˜ë‹¤.v', '_', '_', '_', '_'], ['_', '_', 'Purpose', '_', '_', '_', '_'], ['B-Goal', 'I-Goal', 'O', 'O', 'I-Means', 'I-Means', 'I-Means']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F9zsJryuBRri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "dc2971b6-b2a7-444a-bcbe-9f3f7bef79f0"
      },
      "source": [
        "# 2nd sentence : PURPOSE & INSTRUMENT\n",
        "parsed = parser.parser(ls[1], sent_id='1', result_format='conll')\n",
        "words = parsed[0][0]\n",
        "print(\"ğŸ˜€ Words vector from sentence \",words)\n",
        "q = [-1]*len(parsed)\n",
        "for i in range(len(parsed)):\n",
        "  count=0\n",
        "  for element in parsed[i][3]:\n",
        "    if element.startswith(\"O\"):\n",
        "      count+=1\n",
        "  q[i] = len(words) - count\n",
        "\n",
        "\n",
        "print(\"Number of parsed candidates \",len(parsed))\n",
        "print(q, heapq.nlargest(3, q))\n",
        "print(itemgetter(*[1,5])(parsed))\n",
        "candidates = itemgetter(*[1,8])(parsed)\n",
        "for _ in candidates:\n",
        "  words = _[0]\n",
        "  tagged = _[3]\n",
        "  print(\"tagged vector of candidates: \",tagged)\n",
        "  roles = _[2]\n",
        "  for i in range(len(parsed)):\n",
        "    try:\n",
        "      roles[i] = tagged[i].split(\"-\")[1]\n",
        "    except:\n",
        "      roles[i] = tagged[i].split(\"-\")[0]\n",
        "  print(roles,f'Tagged words for the roles : {tagged}')\n",
        "# roles are selected as the one with purpose and instrument\n",
        "\n",
        "purpose = []\n",
        "instrument = []\n",
        "for _ in range(len(words)):\n",
        "  if roles[_]==\"Purpose\":\n",
        "    purpose.append(words[_])\n",
        "    \n",
        "  elif roles[_]==\"Instrument\":\n",
        "    instrument.append(words[_])\n",
        "    \n",
        "  elif roles[_]!=\"_\": # using í¬í•¨\n",
        "    instrument.append(words[_])\n",
        "print(\"Instrument: \",instrument)\n",
        "print(\"Purpose: \",purpose)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# PURPOSE\n",
        "PURPOSE = ' '.join(purpose)\n",
        "pos = h.pos(PURPOSE)\n",
        "imp = []\n",
        "for tup in pos:\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "PURPOSE_TRUNCATED = ' '.join(imp)\n",
        "print(PURPOSE_TRUNCATED)\n",
        "\n",
        "# INSTRUMENT\n",
        "INSTRUMENT = ' '.join(instrument)\n",
        "pos = h.pos(INSTRUMENT)\n",
        "imp = []\n",
        "for tup in pos:\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "INST_TRUNCATED = ' '.join(imp)\n",
        "print(INST_TRUNCATED)\n",
        "\n",
        "final_string = INST_TRUNCATED+ ' â¡ï¸' + PURPOSE_TRUNCATED \n",
        "print(\"ğŸ˜€ final string to be inserted \", final_string)\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred_logits = sm(masked_logit).view(1,-1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ğŸ˜€ Words vector from sentence  ['ëŒ€ë³¸ì„', 'í”¼í”¼í‹°ë¡œ', 'ì˜®ê¸°ê¸°', 'ì „ì—', 'ìš”ì•½í•˜ê³ ', 'ë¶„ì„í•˜ê¸°', 'ìœ„í•´', 'ìì—°ì–´ì²˜ë¦¬ì˜', 'ìµœì‹ ', 'ê¸°ìˆ ì„', 'ë‹¤ìˆ˜', 'ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.']\n",
            "Number of parsed candidates  9\n",
            "[2, 11, 4, 0, 6, 1, 1, 1, 11] [11, 11, 6]\n",
            "([['ëŒ€ë³¸ì„', 'í”¼í”¼í‹°ë¡œ', 'ì˜®ê¸°ê¸°', 'ì „ì—', 'ìš”ì•½í•˜ê³ ', 'ë¶„ì„í•˜ê¸°', 'ìœ„í•´', 'ìì—°ì–´ì²˜ë¦¬ì˜', 'ìµœì‹ ', 'ê¸°ìˆ ì„', 'ë‹¤ìˆ˜', 'ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.'], ['_', '_', '_', 'ì „.n', '_', '_', '_', '_', '_', '_', '_', '_'], ['_', '_', '_', 'Time_vector', '_', '_', '_', '_', '_', '_', '_', '_'], ['B-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'O', 'B-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event']], [['ëŒ€ë³¸ì„', 'í”¼í”¼í‹°ë¡œ', 'ì˜®ê¸°ê¸°', 'ì „ì—', 'ìš”ì•½í•˜ê³ ', 'ë¶„ì„í•˜ê¸°', 'ìœ„í•´', 'ìì—°ì–´ì²˜ë¦¬ì˜', 'ìµœì‹ ', 'ê¸°ìˆ ì„', 'ë‹¤ìˆ˜', 'ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.'], ['_', '_', '_', '_', '_', '_', '_', '_', 'ìµœì‹ .n', '_', '_', '_'], ['_', '_', '_', '_', '_', '_', '_', '_', 'Relative_time', '_', '_', '_'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Focal_participant', 'O', 'O']])\n",
            "tagged vector of candidates:  ['B-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'O', 'B-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event']\n",
            "['Landmark_event', 'Landmark_event', 'Landmark_event', 'O', 'Event', 'Event', 'Event', 'Event', 'Event', '_', '_', '_'] Tagged words for the roles : ['B-Landmark_event', 'I-Landmark_event', 'I-Landmark_event', 'O', 'B-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event', 'I-Event']\n",
            "tagged vector of candidates:  ['B-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'B-Instrument', 'I-Instrument', 'I-Instrument', 'B-Manner', 'O']\n",
            "['Purpose', 'Purpose', 'Purpose', 'Purpose', 'Purpose', 'Purpose', 'Purpose', 'Instrument', 'Instrument', '_', '_', 'Using'] Tagged words for the roles : ['B-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'I-Purpose', 'B-Instrument', 'I-Instrument', 'I-Instrument', 'B-Manner', 'O']\n",
            "Instrument:  ['ìì—°ì–´ì²˜ë¦¬ì˜', 'ìµœì‹ ', 'ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.']\n",
            "Purpose:  ['ëŒ€ë³¸ì„', 'í”¼í”¼í‹°ë¡œ', 'ì˜®ê¸°ê¸°', 'ì „ì—', 'ìš”ì•½í•˜ê³ ', 'ë¶„ì„í•˜ê¸°', 'ìœ„í•´']\n",
            "ëŒ€ë³¸ í”¼í”¼í‹° ì „ ìš”ì•½ ë¶„ì„\n",
            "ìì—°ì–´ì²˜ë¦¬ ìµœì‹  ì‚¬ìš©\n",
            "ğŸ˜€ final string to be inserted  ìì—°ì–´ì²˜ë¦¬ ìµœì‹  ì‚¬ìš© â¡ï¸ëŒ€ë³¸ í”¼í”¼í‹° ì „ ìš”ì•½ ë¶„ì„\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HxZxxnMiVuKw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "945f2131-26cd-44d3-cd1c-c00ef0bb5f39"
      },
      "source": [
        "# 3rd sentence : Goal - Means\n",
        "parsed = parser.parser(ls[2], sent_id='1', result_format='conll')\n",
        "words = parsed[0][0]\n",
        "print(\"Words vector from sentence \",words)\n",
        "q = [-1]*len(parsed)\n",
        "for i in range(len(parsed)):\n",
        "  count=0\n",
        "  for element in parsed[i][3]:\n",
        "    if element.startswith(\"O\"):\n",
        "      count+=1\n",
        "  q[i] = len(words) - count\n",
        "\n",
        "print(q, heapq.nlargest(3, q))\n",
        "\n",
        "a,b,c=parsed\n",
        "tagged = b[3]\n",
        "for i in range(len(tagged)):\n",
        "  try:\n",
        "    roles[i] = tagged[i].split(\"-\")[1]\n",
        "  except:\n",
        "    roles[i] = tagged[i].split(\"-\")[0]\n",
        "\n",
        "\n",
        "\n",
        "goals = []\n",
        "means = []\n",
        "for _ in range(len(words)):\n",
        "  if roles[_]==\"Goal\":\n",
        "    goals.append(words[_])\n",
        "  if roles[_]=='Means':\n",
        "    means.append(words[_])\n",
        "\n",
        "# MEANS\n",
        "MEANS = ' '.join(means)\n",
        "pos = h.pos(MEANS)\n",
        "imp = []\n",
        "for tup in h.pos(MEANS):\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "MEANS_TRUNCATED = ' '.join(imp)\n",
        "print(MEANS_TRUNCATED)\n",
        "\n",
        "# GOALS\n",
        "GOAL = ' '.join(goals)\n",
        "pos = h.pos(GOAL)\n",
        "imp = []\n",
        "for tup in h.pos(GOAL):\n",
        "  if tup[1]==\"N\":\n",
        "    imp.append(tup[0])\n",
        "GOAL_TRUNCATED = ' '.join(imp)\n",
        "print(GOAL_TRUNCATED)\n",
        "\n",
        "final_string = MEANS_TRUNCATED + ' -- >' + GOAL_TRUNCATED\n",
        "print(\"ğŸ˜€ final string to be inserted\",final_string)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred_logits = sm(masked_logit).view(1,-1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Words vector from sentence  ['ë˜í•œ', 'íŒŒì´ì¬ì—ì„œ', 'íŒŒì›Œí¬ì¸íŠ¸ì˜', 'ì†ŒìŠ¤ì—', 'ì ‘ê·¼í•˜ê¸°', 'ìœ„í•´', 'xml', 'ì½”ë“œë¥¼', 'ì‹¬ì¸µì ìœ¼ë¡œ', 'ë¶„ì„í–ˆìŠµë‹ˆë‹¤.']\n",
            "[2, 8, 3] [8, 3, 2]\n",
            "askdf\n",
            "askdf\n",
            "askdf\n",
            "askdf\n",
            "   \n",
            "ì½”ë“œ ì‹¬ì¸µì  ë¶„ì„\n",
            "íŒŒì´ì¬ íŒŒì›Œí¬ì¸íŠ¸ ì†ŒìŠ¤ ì ‘ê·¼í•˜ê¸°\n",
            "ğŸ˜€ final string to be inserted ì½”ë“œ ì‹¬ì¸µì  ë¶„ì„-->íŒŒì´ì¬ íŒŒì›Œí¬ì¸íŠ¸ ì†ŒìŠ¤ ì ‘ê·¼í•˜ê¸°\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_vBkRqWXnfr",
        "colab_type": "text"
      },
      "source": [
        "## PPTXì— í™œìš©"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ_738Krj4Wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prs = Presentation(\"final_template.pptx\")  # ì›í•˜ëŠ” template ì¢…ë¥˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "slide_0 = prs.slides[0] # ì œë³µ slide (ì œëª© ìŠ¬ë¼ì´ë“œ)\n",
        "slide_2 = prs.slides[2] # ë‘ ë²ˆì§¸ slide"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ_iciyKj4Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slide_2.placeholders.element[3][2][2][1][1].text = \"Two Track Process\" # ì—¬ëŸ ë²ˆì§¸ ìŠ¬ë¼ì´ë“œ ì œëª©\n",
        "slide_2.placeholders.element[5][2][2][1][1].text = \"\"\n",
        "slide_2.placeholders.element[6][2][2][1][1].text = \"\"\n",
        "slide_2.placeholders.element[17][2][2][1][1].text = \"\"\n",
        "slide_2.placeholders.element[18][2][2][1][1].text = \"\"\n",
        "slide_2.placeholders.element[19][2][2][1][1].text = \"TEXT2PPTX\"\n",
        "slide_2.placeholders.element[11][2][2][1][1].text = \"ìì—°ì–´ì²˜ë¦¬ì˜ ìµœì‹  ê¸°ìˆ ì„ ë‹¤ìˆ˜ ì‚¬ìš©\"\n",
        "slide_2.placeholders.element[10][2][2][1][1].text = \"ëŒ€ë³¸ì„ í”¼í”¼í‹°ë¡œ ì˜®ê¸°ê¸° ì „ì— ìš”ì•½í•˜ê³  ë¶„ì„\"\n",
        "slide_2.placeholders.element[14][2][2][1][1].text = \"íŒŒì´ì¬ì—ì„œ íŒŒì›Œí¬ì¸íŠ¸ì˜ ì†ŒìŠ¤ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ xml ì½”ë“œë¥¼ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„\"\n",
        "slide_2.placeholders.element[13][2][2][1][1].text = \"ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ì“°ì¸ ëŒ€ë³¸ì„ í…2í”¼ì— ì œê³µí•˜ë©´ ë†’ì€ ìˆ˜ì¤€ì˜ í”¼í”¼í‹°ë¡œ ì œê³µ\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEgNzSF4Xq8a",
        "colab_type": "text"
      },
      "source": [
        "## êµìœ¡ìš© êµì¬ì— í™œìš©"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRL1bZb4XusT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
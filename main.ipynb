{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonkim313/dataCampusProject-Team10/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_c_ftRNRpuP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> ê³µìœ  ë“œë¼ì´ë¸Œì™€ ì‘ì—… í™˜ê²½ ì—°ê²°\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "obGBWFLnIypX",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "nb_path = '/content/notebook'\n",
        "os.symlink('/content/drive/Shared drives/BigDATA TEAM 10', nb_path)\n",
        "sys.path.insert(0,nb_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8pGPjInRL-g",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> ì‚¬ì „ì— ì„¤ì¹˜ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëª©ë¡\n",
        "\n",
        "\n",
        "    !pip install --target=$nb_path transformers\n",
        "    !apt-get update\n",
        "    !apt-get g++ openjdk-8-jdk \n",
        "    !pip3 install --target=$nb_path konlpy\n",
        "    !pip install --target=$nb_path soykeyword\n",
        "    !pip install --target=$nb_path krwordrank\n",
        "    !pip install --target=$nb_path heapq\n",
        "    !pip install --target=$nb_path kss\n",
        "    !pip install --target=$nb_path bert\n",
        "    !pip install --target=$nb_path textrankr\n",
        "    !pip install --target=$nb_path lexrankr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW_dvLIjPrrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Hannanum, Okt\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import heapq\n",
        "import pandas as pd\n",
        "from operator import itemgetter\n",
        "from collections import deque\n",
        "from ast import literal_eval\n",
        "from collections import defaultdict\n",
        "from soykeyword.lasso import LassoKeywordExtractor\n",
        "from pprint import pprint\n",
        "from krwordrank.word import KRWordRank\n",
        "from copy import deepcopy\n",
        "import kss\n",
        "import itertools\n",
        "import unicodedata\n",
        "import requests\n",
        "from functools import reduce\n",
        "from transformers import *\n",
        "import torch\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "from textrankr import TextRank\n",
        "from lexrankr import LexRank"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RauwSoNrRYvr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f7952a1d-746f-406d-d3e8-2d3fc7bb603a"
      },
      "source": [
        "%cd /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT\n",
        "import frame_parser\n",
        "path=\"/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\"\n",
        "parser = frame_parser.FrameParser(model_path=path, language='ko')\n",
        "h = Hannanum()\n",
        "okt = Okt()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT\n",
            "srl model: framenet\n",
            "language: ko\n",
            "version: 1.2\n",
            "using viterbi: False\n",
            "using masking: True\n",
            "pretrained BERT: bert-base-multilingual-cased\n",
            "using TGT special token: True\n",
            "used dictionary:\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lu2idx.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/kfn1.2_lufrmap.json\n",
            "\t /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
            "...loaded model path: /content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\n",
            "...model is loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar-s1XyrwKmj",
        "colab_type": "text"
      },
      "source": [
        "#### Linked List êµ¬í˜„í•´ì„œ parsed í›„ë³´êµ°ì— ì‚¬ìš©"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gn8ClK-v4uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Node:\n",
        "    def __init__(self, data):\n",
        "        self.words = data[0]\n",
        "        self.tags = data[3]\n",
        "        self.next = None\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str((self.words, self.tags))\n",
        "\n",
        "class LinkedList:\n",
        "  def __init__(self):\n",
        "      self.head = None\n",
        "\n",
        "  def __repr__(self):\n",
        "      node = self.head\n",
        "      nodes = []\n",
        "      while node is not None:\n",
        "          nodes.append(str(node.tags))\n",
        "          node = node.next\n",
        "      nodes.append(\"None\")\n",
        "      return ' -> '.join(nodes)\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl_ThLJhwOS4",
        "colab_type": "text"
      },
      "source": [
        "### Multiple Inheritance by Super()\n",
        "\n",
        "  **Text --> Highlight --> Relation**\n",
        "\n",
        "\n",
        "Text í´ë˜ìŠ¤\n",
        "\n",
        "    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë‹¨ë³„ë¡œ, ë¬¸ì¥ë³„ë¡œ ë‚˜ëˆ„ì–´ì¤Œ\n",
        "\n",
        "Highlight í´ë˜ìŠ¤\n",
        "     \n",
        "     CSS ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì¤‘ì‹¬ë¬¸ì¥ì—ëŠ” underline, ì¤‘ì‹¬ ë‹¨ì–´ì—ëŠ” highlight, ê´€ê³„ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ì–´ë“¤ì—ëŠ” boxë¥¼ ì‚½ì…í•´ì¤€ë‹¤\n",
        "\n",
        "Relation í´ë˜ìŠ¤\n",
        "\n",
        "    frameNETì˜ 807ê°œì˜ ì˜ë¯¸ì—­ì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì–´ë“¤ì˜ ë‹¤ì˜ì„±ì„ ê³ ë ¤í•œ ìš©ë¡€, beginning/ inside/ outside taggingì„ ì´ìš©í•œë‹¤. êµ¬ì ˆ ì‚¬ì´ì˜ ì–¸ì–´ì  ê´€ê³„ì„±ì„ íŒŒì•…í•  ìˆ˜ ìˆìœ¼ë©° ì´ë¥¼ í†µí•´ ìš”ì•½, ì••ì¶•ì„ êµ¬í˜„í•¨.\n",
        "     \n",
        "\n",
        "  Relation.__mro__\n",
        "  result : (__main__.Relation, __main__.Highlight, __main__.Text, object)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_v5o0el7I9ur",
        "colab": {}
      },
      "source": [
        "text = '''\n",
        "í‰ë“±ì€ ììœ ì™€ ë”ë¶ˆì–´ ê·¼ëŒ€ ì‚¬íšŒì˜ í•µì‹¬ ì´ë…ìœ¼ë¡œ ìë¦¬ ì¡ê³ ìˆë‹¤. ì¸ê°„ì€ ê°€ë ¹ ì¸ì¢…ì´ë‚˜ ì„±ë³„ê³¼ ìƒê´€ì—†ì´ ëˆ„êµ¬ë‚˜ í‰ë“±í•˜ë‹¤ê³  ìƒê°í•œë‹¤. ëª¨ë“  ì¸ê°„ì€ í‰ë“±í•˜ë‹¤ê³  ë§í•˜ëŠ”ë°, ì´ ë§ì€ ë¬´ìŠ¨ ëœ»ì¼ê¹Œ? ê·¸ë¦¬ê³  ê·¸ ê·¼ê±°ëŠ” ë¬´ì—‡ì¸ê°€? \n",
        "ì¼ë‹¨ ì´ ë§ì„ ëª¨ë“  ì¸ê°„ì„ ëª¨ë“  ì¸¡ë©´ì—ì„œ ë˜‘ê°™ì´ ëŒ€ìš°í•˜ëŠ” ì ˆëŒ€ì¹™ í‰ë“±ìœ¼ë¡œ ìƒê°í•˜ëŠ” ì´ëŠ” ì—†ë‹¤. ì¸ê°„ì€ ì €ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ê°€ì§€ê³  ëŒ€ì–´ë‚œ ëŠ¥ë ¥ê³¼ ì†Œì§ˆì„ ë˜‘ê°™ê²Œ ë§Œë“¤ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì´ë‹¤. ì ˆëŒ€ì  í‰ë“±ì€ ê°œì¸ì˜ ê°œì„±ì´ëƒ ììœ¨ì„± ë“±ì˜ ê°€ì¹˜ì™€ ì¶©ëŒí•˜ê¸°ë„ í•œë‹¤. í‰ë“±ì— ëŒ€í•œ ìš”êµ¬ëŠ” ëª¨ë“  ë¶ˆí‰ë“±ì„ ì•…ìœ¼ë¡œ ë³´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì¶©ë¶„í•œ ì´ìœ ê°€ ì œì‹œë˜ì§€ ì•Šì€ ë¶ˆí‰ë“±ì„ ì œê±°í•˜ëŠ” ë° ëª©í‘œë¥¼ ë‘ê³  ìˆë‹¤. â€˜ì´ìœ  ì—†ëŠ” ì°¨ë³„ ê¸ˆì§€â€™ë¼ëŠ” ì¡°ê±´ì  í‰ë“± ì›ì¹™ì€ ì°¨ë³„ ëŒ€ìš°ë¥¼ í•  ë•ŒëŠ” ì´ìœ ë¥¼ ì œì‹œí•  ê²ƒì„ ìš”êµ¬í•˜ê³  ìˆë‹¤. ì´ê²ƒì€ ì–´ë–¤ ì´ìœ ê°€ ì œì‹œëœë‹¤ë©´ íŠ¹ì •í•œ ë¶€ë¥˜ì— ì†í•˜ëŠ” ì‚¬ëŒë“¤ì—ê²ŒëŠ” í‰ë“±í•œ ëŒ€ìš°ë¥¼, ê·¸ ë¶€ë¥˜ì— ì†í•˜ì§€ ì•ŠëŠ” ì‚¬ëŒë“¤ì—ê²ŒëŠ” ì°¨ë³„ì € ëŒ€ìš°ë¥¼ í•˜ëŠ” ê²ƒì„ í—ˆìš©í•œë‹¤. ê·¸ë ‡ë‹¤ë©´ ì‚¬ëŒë“¤ì„ íŠ¹ì •í•œ ë¶€ë¥˜ë¡œ êµ¬ë¶„í•˜ëŠ” ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€? ì´ê²ƒì€ ë°”ë¡œ í‰ë“±ì˜ ê·¼ê±°ì— ëŒ€í•œ ë¬¼ìŒì´ë‹¤.\n",
        "ê·¼ëŒ€ì˜ ì—¬ëŸ¬ ì¸ê¶Œ ì„ ì–¸ì— ë‚˜íƒ€ë‚œ í‰ë“± ê°œë…ì€ ê°œì¸ë“¤ ì‚¬ì´ì˜ í‰ë“±ì„±ì„ íƒ€ê³ ë‚œ ìì—°ì  ê¶Œë¦¬ë¡œ ê°„ì£¼í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ ì´ëŸ¬í•œ ìì—°ê¶Œ ì´ë¡ ì€ ë¬´ì—‡ì´ ìì—°ì  ê¶Œë¦¬ì´ê³  ê¶Œë¦¬ì˜ ì¡´ì¬ê°€ ìëª…í•œ ì´ìœ ê°€ ë¬´ì—‡ì¸ì§€ ë“±ì˜ ë¬¸ì œì— ë¶€ë”ªíˆê²Œ ëœë‹¤. ê·¸ë˜ì„œ ë¡¤ìŠ¤ëŠ” ê¸°ì¡´ì˜ ìì—°ê¶Œ ì‚¬ìƒì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ” ë°©ì‹œìœ¼ë¡œ ì¸ê°„ í‰ë“±ì˜ ê·¼ê±°ë¥¼ ë§ˆëŸ°í•˜ë ¤ê³  í•œë‹¤. ê·¸ëŠ” ì–´ë–¤ ê·œì¹™ì´ ê³µí‰í•˜ê³  ì¼ê´€ë˜ê²Œ ìš´ì˜ë˜ë©°, ê·¸ ê·œì¹™ì— ë”°ë¼ ìœ ì‚¬í•œ ê²½ìš°ëŠ” ìœ ì‚¬í•˜ê²Œ ì·¨ê¸‰ëœë‹¤ë©´ í˜•ì‹ì  ì •ì˜ëŠ” ì‹¤í˜„ëœë‹¤ê³  ë³¸ë‹¤. í•˜ì§€ë§Œ ë¡¤ìŠ¤ëŠ” í˜•ì‹ì € ì •ì˜ì— ë”°ë¼ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì •ì˜ë¥¼ ë‹´ë³´í•  ìˆ˜ ì—†ë‹¤ê³  ìƒê°í•œë‹¤. ê·¸ ê·œì¹™ì´ ë” ë†’ì€ ë„ë•ì  ê¶Œìœ„ë¥¼ ì§€ë‹Œ ë‹¤ë¥¸ ì´ë„˜ê³¼ ì¶©ëŒí•  ìˆ˜ ì—ˆê¸°ì—, ì‹¤ì§ˆì  ì •ì˜ê°€ ë³´ì¥ë˜ê¸° ìœ„í•´ì„œëŠ” ê·œì¹™ì˜ ë‚´ìš©ì´ ì¤‘ìš”í•œ ê²ƒì´ë‹¤.\n",
        "ë¡¤ìŠ¤ëŠ” ì¸ê°„ í‰ë“±ì˜ ê·¼ê±°ë¥¼ ì„¤ëª…í•˜ë©´ì„œ ì˜ì—­ ì„±ì§ˆ (range property) ê°œë…ì„ ë„ì…í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì–´ë–¤ ì›ì˜ ë‚´ë¶€ì— ìˆëŠ” ì ë“¤ì€ ê·¸ ìœ„ì¹˜ê°€ ì„œë¡œ ë‹¤ë¥´ì§€ë§Œ ì›ì˜ ë‚´ë¶€ì— ìˆë‹¤ëŠ” ì ì—ì„œ ë™ì¼í•œ ì˜ì—­ ì„±ì§ˆì„ ê°–ëŠ”ë‹¤. ë°˜ë©´ì— ì›ì˜ ë‚´ë¶€ì— ìˆëŠ” ì§‘ê³¼ ì›ì˜ ì™¸ë¶€ì— ì˜€ëŠ” ì ì€ì›ì˜ ê²½ê³„ì„ ì„ ê¸°ì¤€ìœ¼ë¡œ ì„œë¡œ ë‹¤ë¥¸ ì˜ì—­ ì„±ì§ˆì„ ê°–ëŠ”ë‹¤. ê·¸ëŠ” í‰ë“±í•œ ëŒ€ìš°ë¥¼ ë°›ê¸° ìœ„í•œ ì˜ì—­ ì„±ì§ˆë¡œì„œ â€˜ë„ë•ì  ì¸ê²©'ì„ ì œì‹œí•œë‹¤. ë„ë•ì  ì¸ê²©ì´ë€ ë„ë•ì  í˜¸ì†Œê°€ ê°€ëŠ¥í•˜ê³  ê·¸ëŸ° í˜¸ì†Œì— ê´€ì‹¬ì„ ê¸°ì´ëŠ” ëŠ¥ë ¥ì´ ìˆë‹¤ëŠ” ê²ƒì¸ë°, ì´ ëŠ¥ë ¥ì„ ìµœì†Œì¹˜ë§Œ ê°–ê³  ìˆë‹¤ë©´ í‰ë“±í•œ ëŒ€ìš°ì— ëŒ€í•œ ê¶Œí•œì„ ê°–ê²Œ ëœë‹¤. ë„ë•ì  ì¸ê²©ì´ë¼ê³  í•´ì„œ ë„ë•ì ìœ¼ë¡œ í›Œë¥­í•˜ë‹¤ëŠ” ëœ»ì´ ì•„ë‹ˆë¼ ë„ë•ê³¼ ë¬´ê´€í•˜ë‹¤ëŠ” ë§ê³¼ ëŒ€ë¹„ë˜ëŠ” ëœ»ìœ¼ë¡œ ì“°ê³  ìˆë‹¤. ê·¸ëŸ°ë° ì–´ë¦° ì•„ì´ëŠ” ì¸ê²©ì²´ë¡œì„œì˜ ìµœì†Œí•œì˜ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ê³  ìˆëŠ”ì§€ê°€ ë…¼ë€ì´ ë  ìˆ˜ ìˆë‹¤. ì´ì— ëŒ€í•´ ë¡¤ìŠ¤ëŠ” ë„ë•ì  ì¸ê²©ì„ ê·œì •í•˜ëŠ” ìµœì†Œí•œì˜ ìš”êµ¬ ì¡°ê±´ì€ ì ì¬ì  ëŠ¥ë ¥ì´ì§€ ê·¸ê²ƒì˜ ì‹¤í˜„ ì—¬ë¶€ê°€ ì•„ë‹ˆê¸°ì— ì–´ë¦° ì•„ì´ë„ í‰ë“±í•œ ì¡´ì¬ë¼ê³  ë§í•œë‹¤. ì‹±ì–´ëŠ” ìœ„ì™€ ê°™ì€ ë¡¤ìŠ¤ì˜ ì‹œë„ë¥¼ ë¹„íŒí•œë‹¤. ë„ë•ì— ëŒ€í•œ ë¯¼ê°ì„±ì˜ ìˆ˜ì¤€ì€ ì‚¬ëŒì— ë”°ë¼ ë‹¤ë¥´ë‹¤. ê·¸ë˜ì„œ ë„ë•ì  ì¸ê²©ì˜ ëŠ¥ë ¥ì´ ê·¸ë ‡ê²Œ ì¤‘ìš”í•˜ë‹¤ë©´ ê·¸ê²ƒì„ ê°–ì¶˜ ì •ë„ì— ë”°ë¼ ë„ë•ì  ìœ„ê³„ë¥¼ ë‹¤ë¥´ê²Œ í•˜ì§€ ë§ì•„ì•¼ í•  ì´ìœ ê°€ ë¶„ëª…í•˜ì§€ ì•Šë‹¤ê³  ë§í•œë‹¤. \n",
        "'''"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGCJPBUtvXj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Text():\n",
        "    def __init__(self, text):\n",
        "        text = re.sub(\"'\", ' ', text)\n",
        "        paragraphs = text.split('\\n')\n",
        "        self.text = text\n",
        "        self.paragraphs = [i for i in paragraphs if i]\n",
        "        self.docs = [kss.split_sentences(paragraph) for paragraph in paragraphs if kss.split_sentences(paragraph)]\n",
        "        self.newtext = deepcopy(self.text)\n",
        "        print(\"TEXT\")\n",
        "\n",
        "    def findall(self, p, s):\n",
        "        i = s.find(p)\n",
        "        while i != -1:\n",
        "            yield i\n",
        "            i = s.find(p, i + 1)\n",
        "      \n",
        "    def countMatcher(self, sentences, paragraph_no):\n",
        "        paragraph = self.docs[paragraph_no]\n",
        "        total_no = len(paragraph)\n",
        "        vec = [0] * total_no\n",
        "        \n",
        "        for idx, candidate in enumerate(paragraph):\n",
        "            for sentence in sentences:\n",
        "                if candidate.startswith(sentence[:4]):\n",
        "                    vec[idx] += 1\n",
        "        print(\"Vec \",vec)\n",
        "        return vec\n",
        "\n",
        "\n",
        "\n",
        "class Highlight(Text):\n",
        "    def __init__(self, text, candidates=None):\n",
        "        super().__init__(text)\n",
        "        self.candidates = candidates\n",
        "        self.cand = candidates\n",
        "        print(\"Highlight\")\n",
        "\n",
        "    def add_tags(self, underline = False, highlight = True):\n",
        "        if self.cand == None:\n",
        "            conj = 'ê·¸ë¦¬ê³ , ê·¸ëŸ°ë°, ê·¸ëŸ¬ë‚˜, ê·¸ë˜ë„, ê·¸ë˜ì„œ, ë˜ëŠ”, ë°, ì¦‰, ê²Œë‹¤ê°€, ë”°ë¼ì„œ, ë•Œë¬¸ì—, ì•„ë‹ˆë©´, ì™œëƒí•˜ë©´, ë‹¨, ì˜¤íˆë ¤, ë¹„ë¡, ì˜ˆë¥¼ ë“¤ì–´, ë°˜ë©´ì—, í•˜ì§€ë§Œ, ê·¸ë ‡ë‹¤ë©´, ë°”ë¡œ, ì´ì— ëŒ€í•´'\n",
        "            conj = conj.replace(\"'\", \"\")\n",
        "            self.candidates = conj.split(\",\")\n",
        "            self.idx = [(i, i + len(candidate)) for candidate in self.candidates for i in\n",
        "                        self.findall(candidate, self.text)]\n",
        "        else:\n",
        "            self.idx = [(i, i + len(candidate)) for candidate in self.candidates for i in\n",
        "                        self.findall(candidate, self.newtext)]\n",
        "\n",
        "        for i in range(len(self.idx)):\n",
        "            try:\n",
        "                if highligh:\n",
        "                    self.idx = [(start, start + len(candidate)) for candidate in self.candidates for start in\n",
        "                                self.findall(candidate, self.newtext)]\n",
        "                    word = self.newtext[self.idx[i][0]:self.idx[i][1]]\n",
        "                    if highlight and self.cand == None:\n",
        "                        tagged = \" <mark style='background-color:#F9D877'>%s</mark>\" % (word)\n",
        "                    elif highlight:\n",
        "                        tagged = \" <mark style='background-color:#FFD0F2'>%s</mark>\" % (word)\n",
        "                if underline:\n",
        "                    self.idx = [(start, start + len(candidate)) for candidate in self.candidates for start in\n",
        "                                self.findall(candidate, self.newtext)]\n",
        "                    word = self.newtext[self.idx[i][0]:self.idx[i][1]]\n",
        "                    tagged = \"<u style='text-decoration:underline; text-decoration-color:#906fa8; font-weight: bold; text-decoration-style: wavy'>%s</u>\" % (word)\n",
        "                \n",
        "                self.newtext = tagged.join([self.newtext[:self.idx[i][0]], self.newtext[self.idx[i][1]:]])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        return '\\n'.join(self.newtext.split(\"\\n\"))\n",
        "\n",
        "\n",
        "class Relation(Highlight):\n",
        "    def __init__(self, text, candidates=None, num=20):\n",
        "\n",
        "        super().__init__(text, candidates)\n",
        "        \n",
        "        wordrank_extractor = KRWordRank(min_count=4, max_length=10)\n",
        "        self.keywords, rank, graph = wordrank_extractor.extract(self.paragraphs, num_keywords=num)\n",
        "        self.path = \"/content/drive/Shared drives/BigDATA TEAM 10/OpenInformationExtraction\"\n",
        "        p = []\n",
        "        kw = []\n",
        "        for k, v in self.keywords.items():\n",
        "            p.append(okt.pos(k))\n",
        "            kw.append(k)\n",
        "        words = self.text.split(' ')\n",
        "        s = set()\n",
        "        keylist = [word for i in kw for word in words if i in word]\n",
        "        for i in keylist:\n",
        "            s.add(i)\n",
        "        p = [okt.pos(word) for word in s]\n",
        "        s = set()\n",
        "        for idx in range(len(p)):\n",
        "            ls = p[idx]\n",
        "            for j in range(len(ls)):\n",
        "                tag = ls[j][1]\n",
        "                word = ls[j][0]\n",
        "                if tag == \"Noun\":\n",
        "                    s.add(word)\n",
        "        self.keys = []\n",
        "        for temp in s:\n",
        "            self.keys.append(\" \" + temp)\n",
        "        print(\"KEYS: \", self.keys)\n",
        "\n",
        "    def frameParse(self, id):\n",
        "        parser = frame_parser.FrameParser(model_path=self.path, language='ko')\n",
        "        ps = parser.parser(self.docs[id], sent_id='1', result_format='conll')\n",
        "        return ps\n",
        "\n",
        "    def extractFrame(self):\n",
        "        self.final = {}\n",
        "        for paragraph in self.docs:\n",
        "            print(\"PARAGRAPH: \", self.docs)\n",
        "            for idx in range(len(paragraph)):\n",
        "                parsed = frameParse(paragraph[idx])  # candidates ìƒì„±\n",
        "                self.final.setdefault(idx, str)\n",
        "                parsedList = LinkedList()\n",
        "                for j in range(len(parsed)):\n",
        "                    parsed_candidate = parsed[j]\n",
        "                    new_node = Node(parsed_candidate)\n",
        "                    if j == 0:\n",
        "                        old_node = new_node\n",
        "                        parsedList.head = old_node\n",
        "                    elif j == len(parsed) - 1:\n",
        "                        old_node.next = new_node\n",
        "                        new_node.next = None\n",
        "                        print(idx, '  ', parsedList)\n",
        "                        self.final[idx] = parsedList\n",
        "                    else:\n",
        "                        old_node.next = new_node\n",
        "                        old_node = new_node\n",
        "\n",
        "    def findConsecutiveBIO(self, words, tag):\n",
        "        began = False\n",
        "        count = 1\n",
        "        self.que = deque(words)\n",
        "        for i in range(len(words)):\n",
        "            if tag[i] == 'O' and not began:\n",
        "                self.que.popleft()\n",
        "                began = False\n",
        "            if tag[i] == 'O' and began:\n",
        "                self.que.pop()\n",
        "                began = False\n",
        "            if tag[i].startswith('B'):\n",
        "                began = True\n",
        "            if began & tag[i].startswith('I'):\n",
        "                count += 1\n",
        "        return self.que\n",
        "\n",
        "    def extractRelation(self):\n",
        "        s = \"\"\n",
        "        self.res = [] * 20\n",
        "        for k, v in self.final.items():\n",
        "            a = v.head\n",
        "            try:\n",
        "                while a is not None:\n",
        "                    i = 0\n",
        "                    temp = \" \"\n",
        "                    if len(a.words) == len(a.tags):\n",
        "                        q = findConsecutiveBIO(a.words, a.tags)\n",
        "                        print(f\"The que {q}\")\n",
        "                    else:\n",
        "                        print(\"ERROR OCCURED\")\n",
        "\n",
        "                    count = len(a.words)\n",
        "                    for tag in a.tags:\n",
        "                        if tag.startswith(\"O\"):\n",
        "                            count -= 1\n",
        "                    if count > len(a.words) * 0.45:\n",
        "                        print(f\"The threshold is reached !!ğŸ˜ The count is {count}\")\n",
        "                        temp = \" \".join(q)\n",
        "                        words = a.words\n",
        "                        tags = a.tags\n",
        "                    else:\n",
        "                        temp = None\n",
        "                        words = None\n",
        "                        tags = None\n",
        "                    self.res[i] = (words, tag, temp)\n",
        "                    i+=1\n",
        "                    a = a.next\n",
        "            except:\n",
        "                pass\n",
        "        self.res = [j for j in self.res if j]\n",
        "\n",
        "    def roles(self):\n",
        "        for k, tup in self.res.items():\n",
        "            a, b, c = tup\n",
        "            roles = [0] * len(b)\n",
        "            words = [0] * len(b)\n",
        "            for i in range(len(b)):\n",
        "                try:\n",
        "                    roles[i] = b[i].split(\"-\")[1]\n",
        "                except:\n",
        "                    roles[i] = b[i].split(\"-\")[0]\n",
        "            print(roles)\n",
        "            for _ in roles:\n",
        "                pass\n",
        "\n",
        "class Summarize(Highlight):\n",
        "    def __init__(self, text, paragraph_no):\n",
        "      super().__init__(text)\n",
        "      self.paragraph_no = paragraph_no\n",
        "      self.txt = self.paragraphs[self.paragraph_no]\n",
        "\n",
        "    def summarize(self):\n",
        "        url = \"https://api.smrzr.io/summarize?ratio=0.15\"\n",
        "        headers = {\n",
        "            'content-type': 'raw/text',\n",
        "            'origin': 'https://smrzr.io',\n",
        "            'referer': 'https://smrzr.io/',\n",
        "            'sec-fetch-dest': 'empty',\n",
        "            'sec-fetch-mode': 'cors',\n",
        "            'sec-fetch-site': 'same-site',\n",
        "            \"user-agent\": \"Mozilla/5.0\"\n",
        "        }\n",
        "        resp = requests.post(url, headers=headers, data= self.txt.encode('utf-8'))\n",
        "        assert resp.status_code == 200\n",
        "        summary = resp.json()['summary']\n",
        "        temp = summary.split('\\n')\n",
        "        print(\"BERT: \", temp)\n",
        "        return temp\n",
        "\n",
        "\n",
        "    def summarizeTextRank(self, max=1):\n",
        "        tr = TextRank(self.txt)\n",
        "        \n",
        "        summary = tr.summarize(max).split('\\n')\n",
        "        print(\"Textrank: \",summary)\n",
        "        return summary\n",
        "\n",
        "\n",
        "    def summarizeLexRank(self):\n",
        "        lr = LexRank()\n",
        "        lr.summarize(self.txt)\n",
        "        summaries = lr.probe()\n",
        "        print(\"Lexrank: \",summaries)\n",
        "        return summaries\n",
        "\n",
        "    def ensembleSummarize(self):\n",
        "        a = np.array(self.countMatcher(self.summarize(), self.paragraph_no))\n",
        "        b = np.array(self.countMatcher(self.summarizeLexRank(), self.paragraph_no))\n",
        "        c = np.array(self.countMatcher(self.summarizeTextRank(),self.paragraph_no))\n",
        "        result= a+b+c\n",
        "        i, = np.where(result == max(result))\n",
        "        # print(\"Index \",i[0])\n",
        "        # print(\"text \",self.txt)\n",
        "        return self.docs[self.paragraph_no][i[0]], i\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsGrdHU5YEN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = re.sub(\"'\", ' ', text)\n",
        "paragraphs = text.split('\\n')\n",
        "paragraphs = [i for i in paragraphs if i]\n",
        "counts = len(paragraphs)\n",
        "print(\"counts \",counts)\n",
        "from collections import defaultdict\n",
        "di = defaultdict(list)\n",
        "# di[idx].append()\n",
        "for idx in range(counts):\n",
        "  summarizer = Summarize(text, idx)\n",
        "\n",
        "  text, id = summarizer.ensembleSummarize()\n",
        "\n",
        "  print(\"res \",text, id[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GReuNdb-TtD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrwJKcTB-S8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S7zGTQO4BUO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "240b4064-5948-41dd-aa8e-49ce86d749c6"
      },
      "source": [
        "# 1st sentence : GOALS & MEANS \n",
        "obj = \"í‰ë“±ì€ ììœ ì™€ ë”ë¶ˆì–´ ê·¼ëŒ€ ì‚¬íšŒì˜ í•µì‹¬ ì´ë…ìœ¼ë¡œ ìë¦¬ ì¡ê³ ìˆë‹¤ .\"\n",
        "parsed = parser.parser(obj, sent_id='1', result_format='conll')\n",
        "words = parsed[0][0]\n",
        "print(\"ğŸ˜€ Words vector from sentence \",words)\n",
        "q = [-1]*len(parsed)\n",
        "for i in range(len(parsed)):\n",
        "  count=0\n",
        "  for element in parsed[i][3]:\n",
        "    if element.startswith(\"O\"):\n",
        "      count+=1\n",
        "  q[i] = len(words) - count\n",
        "hq = heapq.nlargest(2, q)\n",
        "\n",
        "\n",
        "print(\"Number of parsed candidates \",len(parsed))\n",
        "print(q, heapq.nlargest(2, q)) # ì²«ë²ˆì§¸ ê²½ìš° ì‚¬ìš©\n",
        "\n",
        "\n",
        "words = parsed[0][0]\n",
        "roles = parsed[0][2]\n",
        "tagged = parsed[0][3]\n",
        "for idx in range(len(tagged)):\n",
        "  try:\n",
        "    roles[i] = tagged[i].split(\"-\")[1]\n",
        "  except:\n",
        "    roles[i] = tagged[i].split(\"-\")[0]\n",
        "\n",
        "print(\"roles \",roles)\n",
        "\n",
        "goals = []\n",
        "means = []\n",
        "purpose = []\n",
        "instrument = []\n",
        "es = []\n",
        "for _ in range(len(words)):\n",
        "  if roles[_]==\"Goal\":\n",
        "    goals.append(words[_])\n",
        "  elif roles[_]=='Means':\n",
        "    means.append(words[_])\n",
        "  elif roles[_]==\"Purpose\":\n",
        "    purpose.append(words[_])\n",
        "  elif roles[_]==\"Instrument\":\n",
        "    instrument.append(words[_])\n",
        "  elif roles[_]!=\"_\": # using í¬í•¨\n",
        "    instrument.append(words[_])\n",
        "  else:\n",
        "    es.append(words[_])\n",
        "# # MEANS\n",
        "# MEANS = ' '.join(means)\n",
        "# pos = h.pos(MEANS)\n",
        "# imp = []\n",
        "# for tup in h.pos(MEANS):\n",
        "#   if tup[1]==\"N\":\n",
        "#     imp.append(tup[0])\n",
        "# MEANS_TRUNCATED = ' '.join(imp)\n",
        "# print(MEANS_TRUNCATED)\n",
        "\n",
        "# # GOALS\n",
        "# GOAL = ' '.join(goals)\n",
        "# pos = h.pos(GOAL)\n",
        "# imp = []\n",
        "# for tup in h.pos(GOAL):\n",
        "#   if tup[1]==\"N\":\n",
        "#     imp.append(tup[0])\n",
        "# GOAL_TRUNCATED = ' '.join(imp)\n",
        "# print(GOAL_TRUNCATED)\n",
        "\n",
        "# final_string = MEANS_TRUNCATED + ' -- >' + GOAL_TRUNCATED\n",
        "# print(\"ğŸ˜€ final string to be inserted\",final_string)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred_logits = sm(masked_logit).view(1,-1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ğŸ˜€ Words vector from sentence  ['í‰ë“±ì€', 'ììœ ì™€', 'ë”ë¶ˆì–´', 'ê·¼ëŒ€', 'ì‚¬íšŒì˜', 'í•µì‹¬', 'ì´ë…ìœ¼ë¡œ', 'ìë¦¬', 'ì¡ê³ ìˆë‹¤', '.']\n",
            "Number of parsed candidates  5\n",
            "[0, 2, 2, 4, 4] [4, 4]\n",
            "roles  ['_', 'Strictness', '_', '_', 'O', '_', '_', '_', '_', '_']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knURW0UUBbnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f34a01cf-4bc9-46fb-9f14-75c4e3fdfcc7"
      },
      "source": [
        "relation = Relation(text)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEXT\n",
            "Highlight\n",
            "KEYS:  [' ì‹œí•œ', ' ì²´', ' ì œì‹œ', ' ì ', ' ê²ƒ', ' ì˜ì—­', ' ëª¨ë“ ', ' ê·¼ê±°', ' ì¸ê°„', ' í‰ë“±', ' ì •ì˜', ' ë„ë•', ' ëŠ¥ë ¥', ' ëŒ€ìš°', ' ë¡¤ìŠ¤', ' í‰ë“±ì„±', ' ë¶ˆí‰ë“±', ' ì¸ê²©', ' ëŒ€í•œ', ' ë¡œì„œ', ' ê·œì¹™', ' ì„±ì§ˆ', ' ì´ìœ ', ' ì›']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqMFukCKCFW_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d1e1d4ec-29e6-4473-ea57-0aeb587ee752"
      },
      "source": [
        "relation.extractRelation()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-f0b8a0fbfd00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrelation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractRelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-110-a8b7efb71b16>\u001b[0m in \u001b[0;36mextractRelation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Relation' object has no attribute 'final'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzQ2APEFDnRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}